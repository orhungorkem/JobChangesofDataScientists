{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chief-victorian",
   "metadata": {},
   "source": [
    "Name: Orhun Görkem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "willing-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"aug_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-december",
   "metadata": {},
   "source": [
    "Dataset reference: https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "horizontal-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>city_115</td>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>7386</td>\n",
       "      <td>city_173</td>\n",
       "      <td>0.878</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>31398</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>24576</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>5756</td>\n",
       "      <td>city_65</td>\n",
       "      <td>0.802</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>500-999</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>23834</td>\n",
       "      <td>city_67</td>\n",
       "      <td>0.855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollee_id      city  city_development_index gender  \\\n",
       "0             8949  city_103                   0.920   Male   \n",
       "1            29725   city_40                   0.776   Male   \n",
       "2            11561   city_21                   0.624    NaN   \n",
       "3            33241  city_115                   0.789    NaN   \n",
       "4              666  city_162                   0.767   Male   \n",
       "...            ...       ...                     ...    ...   \n",
       "19153         7386  city_173                   0.878   Male   \n",
       "19154        31398  city_103                   0.920   Male   \n",
       "19155        24576  city_103                   0.920   Male   \n",
       "19156         5756   city_65                   0.802   Male   \n",
       "19157        23834   city_67                   0.855    NaN   \n",
       "\n",
       "           relevent_experience enrolled_university education_level  \\\n",
       "0      Has relevent experience       no_enrollment        Graduate   \n",
       "1       No relevent experience       no_enrollment        Graduate   \n",
       "2       No relevent experience    Full time course        Graduate   \n",
       "3       No relevent experience                 NaN        Graduate   \n",
       "4      Has relevent experience       no_enrollment         Masters   \n",
       "...                        ...                 ...             ...   \n",
       "19153   No relevent experience       no_enrollment        Graduate   \n",
       "19154  Has relevent experience       no_enrollment        Graduate   \n",
       "19155  Has relevent experience       no_enrollment        Graduate   \n",
       "19156  Has relevent experience       no_enrollment     High School   \n",
       "19157   No relevent experience       no_enrollment  Primary School   \n",
       "\n",
       "      major_discipline experience company_size    company_type last_new_job  \\\n",
       "0                 STEM        >20          NaN             NaN            1   \n",
       "1                 STEM         15        50-99         Pvt Ltd           >4   \n",
       "2                 STEM          5          NaN             NaN        never   \n",
       "3      Business Degree         <1          NaN         Pvt Ltd        never   \n",
       "4                 STEM        >20        50-99  Funded Startup            4   \n",
       "...                ...        ...          ...             ...          ...   \n",
       "19153       Humanities         14          NaN             NaN            1   \n",
       "19154             STEM         14          NaN             NaN            4   \n",
       "19155             STEM        >20        50-99         Pvt Ltd            4   \n",
       "19156              NaN         <1      500-999         Pvt Ltd            2   \n",
       "19157              NaN          2          NaN             NaN            1   \n",
       "\n",
       "       training_hours  target  \n",
       "0                  36     1.0  \n",
       "1                  47     0.0  \n",
       "2                  83     0.0  \n",
       "3                  52     1.0  \n",
       "4                   8     0.0  \n",
       "...               ...     ...  \n",
       "19153              42     1.0  \n",
       "19154              52     1.0  \n",
       "19155              44     0.0  \n",
       "19156              97     0.0  \n",
       "19157             127     0.0  \n",
       "\n",
       "[19158 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-council",
   "metadata": {},
   "source": [
    "Since enrollee id is non-relevant, we may drop that column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "obvious-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['enrollee_id'],axis=1)\n",
    "#not dropping city because development index may not be the only significant feature about the city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-thermal",
   "metadata": {},
   "source": [
    "Checking the types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changing-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "pureNum=[]\n",
    "strList=[]\n",
    "for i in df.columns:\n",
    "    hasString = False\n",
    "    for j in df[i]:\n",
    "        if(isinstance(j,str)):\n",
    "            hasString = True\n",
    "    if not hasString:\n",
    "        pureNum.append(i)\n",
    "    else:\n",
    "        strList.append(i)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-edward",
   "metadata": {},
   "source": [
    "Eliminating rows with nan.  \n",
    "**We can also put averages to nans if data is not sufficient.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indie-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_46</td>\n",
       "      <td>0.762</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>7</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>5000-9999</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>1</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>9</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>city_160</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Female</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>10</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Public Sector</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Female</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>7</td>\n",
       "      <td>10/49</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8955 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  city_development_index  gender      relevent_experience  \\\n",
       "0      city_40                   0.776    Male   No relevent experience   \n",
       "1     city_162                   0.767    Male  Has relevent experience   \n",
       "2      city_46                   0.762    Male  Has relevent experience   \n",
       "3     city_103                   0.920    Male  Has relevent experience   \n",
       "4     city_103                   0.920    Male  Has relevent experience   \n",
       "...        ...                     ...     ...                      ...   \n",
       "8950   city_21                   0.624    Male   No relevent experience   \n",
       "8951  city_103                   0.920    Male  Has relevent experience   \n",
       "8952  city_160                   0.920  Female  Has relevent experience   \n",
       "8953  city_103                   0.920  Female  Has relevent experience   \n",
       "8954  city_103                   0.920    Male  Has relevent experience   \n",
       "\n",
       "     enrolled_university education_level major_discipline experience  \\\n",
       "0          no_enrollment        Graduate             STEM         15   \n",
       "1          no_enrollment         Masters             STEM        >20   \n",
       "2          no_enrollment        Graduate             STEM         13   \n",
       "3          no_enrollment        Graduate             STEM          7   \n",
       "4          no_enrollment        Graduate             STEM          5   \n",
       "...                  ...             ...              ...        ...   \n",
       "8950    Full time course        Graduate             STEM          1   \n",
       "8951       no_enrollment         Masters             STEM          9   \n",
       "8952       no_enrollment        Graduate             STEM         10   \n",
       "8953       no_enrollment        Graduate       Humanities          7   \n",
       "8954       no_enrollment        Graduate             STEM        >20   \n",
       "\n",
       "     company_size    company_type last_new_job  training_hours  target  \n",
       "0           50-99         Pvt Ltd           >4              47     0.0  \n",
       "1           50-99  Funded Startup            4               8     0.0  \n",
       "2             <10         Pvt Ltd           >4              18     1.0  \n",
       "3           50-99         Pvt Ltd            1              46     1.0  \n",
       "4       5000-9999         Pvt Ltd            1             108     0.0  \n",
       "...           ...             ...          ...             ...     ...  \n",
       "8950      100-500         Pvt Ltd            1              52     1.0  \n",
       "8951        50-99         Pvt Ltd            1              36     1.0  \n",
       "8952      100-500   Public Sector            3              23     0.0  \n",
       "8953        10/49  Funded Startup            1              25     0.0  \n",
       "8954        50-99         Pvt Ltd            4              44     0.0  \n",
       "\n",
       "[8955 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "dropped=[]\n",
    "for i,row in df.iterrows():\n",
    "    \n",
    "    for j in df.columns:\n",
    "        if isNaN(row[j]):\n",
    "            if i not in dropped:\n",
    "                dropped.append(i)\n",
    "                    \n",
    "                    \n",
    "df = df.drop(dropped)\n",
    "df.index = [i for i in range(df.shape[0])] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-purse",
   "metadata": {},
   "source": [
    "Now we revealed the columns consisting of numbers. We are normalizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "according-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_40</td>\n",
       "      <td>0.654691</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_162</td>\n",
       "      <td>0.636727</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_46</td>\n",
       "      <td>0.626747</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>7</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>5000-9999</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.319403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>city_21</td>\n",
       "      <td>0.351297</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>1</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>9</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>city_160</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>Female</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>10</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Public Sector</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>Female</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>7</td>\n",
       "      <td>10/49</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>4</td>\n",
       "      <td>0.128358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8955 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  city_development_index  gender      relevent_experience  \\\n",
       "0      city_40                0.654691    Male   No relevent experience   \n",
       "1     city_162                0.636727    Male  Has relevent experience   \n",
       "2      city_46                0.626747    Male  Has relevent experience   \n",
       "3     city_103                0.942116    Male  Has relevent experience   \n",
       "4     city_103                0.942116    Male  Has relevent experience   \n",
       "...        ...                     ...     ...                      ...   \n",
       "8950   city_21                0.351297    Male   No relevent experience   \n",
       "8951  city_103                0.942116    Male  Has relevent experience   \n",
       "8952  city_160                0.942116  Female  Has relevent experience   \n",
       "8953  city_103                0.942116  Female  Has relevent experience   \n",
       "8954  city_103                0.942116    Male  Has relevent experience   \n",
       "\n",
       "     enrolled_university education_level major_discipline experience  \\\n",
       "0          no_enrollment        Graduate             STEM         15   \n",
       "1          no_enrollment         Masters             STEM        >20   \n",
       "2          no_enrollment        Graduate             STEM         13   \n",
       "3          no_enrollment        Graduate             STEM          7   \n",
       "4          no_enrollment        Graduate             STEM          5   \n",
       "...                  ...             ...              ...        ...   \n",
       "8950    Full time course        Graduate             STEM          1   \n",
       "8951       no_enrollment         Masters             STEM          9   \n",
       "8952       no_enrollment        Graduate             STEM         10   \n",
       "8953       no_enrollment        Graduate       Humanities          7   \n",
       "8954       no_enrollment        Graduate             STEM        >20   \n",
       "\n",
       "     company_size    company_type last_new_job  training_hours  target  \n",
       "0           50-99         Pvt Ltd           >4        0.137313     0.0  \n",
       "1           50-99  Funded Startup            4        0.020896     0.0  \n",
       "2             <10         Pvt Ltd           >4        0.050746     1.0  \n",
       "3           50-99         Pvt Ltd            1        0.134328     1.0  \n",
       "4       5000-9999         Pvt Ltd            1        0.319403     0.0  \n",
       "...           ...             ...          ...             ...     ...  \n",
       "8950      100-500         Pvt Ltd            1        0.152239     1.0  \n",
       "8951        50-99         Pvt Ltd            1        0.104478     1.0  \n",
       "8952      100-500   Public Sector            3        0.065672     0.0  \n",
       "8953        10/49  Funded Startup            1        0.071642     0.0  \n",
       "8954        50-99         Pvt Ltd            4        0.128358     0.0  \n",
       "\n",
       "[8955 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in pureNum:\n",
    "    col = df[i]\n",
    "    col = col - min(col)\n",
    "    col = col / max(col)\n",
    "    df[i] = col\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-portal",
   "metadata": {},
   "source": [
    "**Company size, experience etc may be put in integer form instead of one hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-advice",
   "metadata": {},
   "source": [
    "It is the turn for other columns. They should be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "infinite-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cellular-specification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654691</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.636727</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626747</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.319403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>0.351297</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.071642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.128358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8955 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      city_development_index  training_hours  target    0    1    2    3    4  \\\n",
       "0                   0.654691        0.137313     0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1                   0.636727        0.020896     0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2                   0.626747        0.050746     1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3                   0.942116        0.134328     1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4                   0.942116        0.319403     0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...                      ...             ...     ...  ...  ...  ...  ...  ...   \n",
       "8950                0.351297        0.152239     1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8951                0.942116        0.104478     1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8952                0.942116        0.065672     0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8953                0.942116        0.071642     0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8954                0.942116        0.128358     0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        5    6  ...    2    3    4    5    0    1    2    3    4    5  \n",
       "0     0.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2     0.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3     1.0  0.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     1.0  0.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "8950  0.0  0.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8951  1.0  0.0  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8952  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "8953  1.0  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8954  1.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[8955 rows x 178 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "encoder = OneHotEncoder()\n",
    "for i in df.columns:\n",
    "    if i in pureNum:\n",
    "        continue\n",
    "    \n",
    "    df[i]= le.fit_transform(df[i])\n",
    "    enc_df = encoder.fit_transform(df[[i]]).toarray()\n",
    "    enc_df = pd.DataFrame(enc_df)\n",
    "    df = pd.concat([df,enc_df],axis=1)\n",
    "    \n",
    "  \n",
    "df = df.drop(columns=strList)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "massive-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-bikini",
   "metadata": {},
   "source": [
    "Matrix form of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hired-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'],axis=1).to_numpy()\n",
    "y = df['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-nursing",
   "metadata": {},
   "source": [
    "## BUILDING THE NEURAL NETWORK  WITH KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-quality",
   "metadata": {},
   "source": [
    "First, apply the embedded library methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "strong-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "invalid-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "peripheral-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-clinton",
   "metadata": {},
   "source": [
    "Here, we contruct the neural network model.  \n",
    "We specify the number of activation nodes in each layer and activation function.  \n",
    "Input dim is the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "everyday-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "behavioral-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "717/717 [==============================] - 1s 900us/step - loss: 0.4380 - accuracy: 0.8405\n",
      "Epoch 2/150\n",
      "717/717 [==============================] - 1s 859us/step - loss: 0.3572 - accuracy: 0.8603\n",
      "Epoch 3/150\n",
      "717/717 [==============================] - 1s 868us/step - loss: 0.3519 - accuracy: 0.8610\n",
      "Epoch 4/150\n",
      "717/717 [==============================] - 1s 866us/step - loss: 0.3350 - accuracy: 0.8639\n",
      "Epoch 5/150\n",
      "717/717 [==============================] - 1s 868us/step - loss: 0.3370 - accuracy: 0.8620\n",
      "Epoch 6/150\n",
      "717/717 [==============================] - 1s 912us/step - loss: 0.3205 - accuracy: 0.8675\n",
      "Epoch 7/150\n",
      "717/717 [==============================] - 1s 889us/step - loss: 0.3255 - accuracy: 0.8694\n",
      "Epoch 8/150\n",
      "717/717 [==============================] - 1s 942us/step - loss: 0.3215 - accuracy: 0.8679\n",
      "Epoch 9/150\n",
      "717/717 [==============================] - 1s 954us/step - loss: 0.3228 - accuracy: 0.8676\n",
      "Epoch 10/150\n",
      "717/717 [==============================] - 1s 948us/step - loss: 0.3206 - accuracy: 0.8692\n",
      "Epoch 11/150\n",
      "717/717 [==============================] - 1s 982us/step - loss: 0.3204 - accuracy: 0.8679\n",
      "Epoch 12/150\n",
      "717/717 [==============================] - 1s 959us/step - loss: 0.2945 - accuracy: 0.8806\n",
      "Epoch 13/150\n",
      "717/717 [==============================] - 1s 935us/step - loss: 0.3159 - accuracy: 0.8732\n",
      "Epoch 14/150\n",
      "717/717 [==============================] - 1s 944us/step - loss: 0.3076 - accuracy: 0.87510s - loss: 0.3077 - accuracy: 0.87\n",
      "Epoch 15/150\n",
      "717/717 [==============================] - 1s 947us/step - loss: 0.2942 - accuracy: 0.8802\n",
      "Epoch 16/150\n",
      "717/717 [==============================] - 1s 954us/step - loss: 0.2935 - accuracy: 0.8795\n",
      "Epoch 17/150\n",
      "717/717 [==============================] - 1s 907us/step - loss: 0.2951 - accuracy: 0.8791\n",
      "Epoch 18/150\n",
      "717/717 [==============================] - 1s 872us/step - loss: 0.2859 - accuracy: 0.8847\n",
      "Epoch 19/150\n",
      "717/717 [==============================] - 1s 887us/step - loss: 0.2910 - accuracy: 0.8787\n",
      "Epoch 20/150\n",
      "717/717 [==============================] - 1s 864us/step - loss: 0.2956 - accuracy: 0.8758\n",
      "Epoch 21/150\n",
      "717/717 [==============================] - 1s 917us/step - loss: 0.2960 - accuracy: 0.8779\n",
      "Epoch 22/150\n",
      "717/717 [==============================] - 1s 814us/step - loss: 0.2880 - accuracy: 0.8789\n",
      "Epoch 23/150\n",
      "717/717 [==============================] - 1s 885us/step - loss: 0.2809 - accuracy: 0.8847\n",
      "Epoch 24/150\n",
      "717/717 [==============================] - 1s 879us/step - loss: 0.2798 - accuracy: 0.8874\n",
      "Epoch 25/150\n",
      "717/717 [==============================] - 1s 836us/step - loss: 0.2825 - accuracy: 0.8874\n",
      "Epoch 26/150\n",
      "717/717 [==============================] - 1s 872us/step - loss: 0.2718 - accuracy: 0.8912\n",
      "Epoch 27/150\n",
      "717/717 [==============================] - 1s 875us/step - loss: 0.2787 - accuracy: 0.8865\n",
      "Epoch 28/150\n",
      "717/717 [==============================] - 1s 900us/step - loss: 0.2755 - accuracy: 0.8842\n",
      "Epoch 29/150\n",
      "717/717 [==============================] - 1s 932us/step - loss: 0.2808 - accuracy: 0.8868\n",
      "Epoch 30/150\n",
      "717/717 [==============================] - 1s 918us/step - loss: 0.2746 - accuracy: 0.8867\n",
      "Epoch 31/150\n",
      "717/717 [==============================] - 1s 923us/step - loss: 0.2743 - accuracy: 0.89070s - loss: 0.2750 - accura\n",
      "Epoch 32/150\n",
      "717/717 [==============================] - 1s 948us/step - loss: 0.2670 - accuracy: 0.8900\n",
      "Epoch 33/150\n",
      "717/717 [==============================] - 1s 912us/step - loss: 0.2676 - accuracy: 0.8872\n",
      "Epoch 34/150\n",
      "717/717 [==============================] - 1s 919us/step - loss: 0.2616 - accuracy: 0.8953\n",
      "Epoch 35/150\n",
      "717/717 [==============================] - 1s 985us/step - loss: 0.2615 - accuracy: 0.8942\n",
      "Epoch 36/150\n",
      "717/717 [==============================] - 1s 919us/step - loss: 0.2703 - accuracy: 0.8885\n",
      "Epoch 37/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2590 - accuracy: 0.8963\n",
      "Epoch 38/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2708 - accuracy: 0.8842\n",
      "Epoch 39/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2529 - accuracy: 0.8983\n",
      "Epoch 40/150\n",
      "717/717 [==============================] - 1s 910us/step - loss: 0.2541 - accuracy: 0.8997\n",
      "Epoch 41/150\n",
      "717/717 [==============================] - 1s 940us/step - loss: 0.2631 - accuracy: 0.8922\n",
      "Epoch 42/150\n",
      "717/717 [==============================] - 1s 989us/step - loss: 0.2495 - accuracy: 0.9002\n",
      "Epoch 43/150\n",
      "717/717 [==============================] - 1s 918us/step - loss: 0.2608 - accuracy: 0.8941\n",
      "Epoch 44/150\n",
      "717/717 [==============================] - 1s 895us/step - loss: 0.2613 - accuracy: 0.8929\n",
      "Epoch 45/150\n",
      "717/717 [==============================] - 1s 844us/step - loss: 0.2522 - accuracy: 0.8970\n",
      "Epoch 46/150\n",
      "717/717 [==============================] - 1s 918us/step - loss: 0.2544 - accuracy: 0.8951\n",
      "Epoch 47/150\n",
      "717/717 [==============================] - 1s 925us/step - loss: 0.2480 - accuracy: 0.8936\n",
      "Epoch 48/150\n",
      "717/717 [==============================] - 1s 876us/step - loss: 0.2345 - accuracy: 0.9014\n",
      "Epoch 49/150\n",
      "717/717 [==============================] - 1s 934us/step - loss: 0.2473 - accuracy: 0.8963\n",
      "Epoch 50/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2346 - accuracy: 0.9031\n",
      "Epoch 51/150\n",
      "717/717 [==============================] - 1s 989us/step - loss: 0.2480 - accuracy: 0.8994\n",
      "Epoch 52/150\n",
      "717/717 [==============================] - 1s 980us/step - loss: 0.2464 - accuracy: 0.90170s - loss:\n",
      "Epoch 53/150\n",
      "717/717 [==============================] - 1s 998us/step - loss: 0.2414 - accuracy: 0.9048\n",
      "Epoch 54/150\n",
      "717/717 [==============================] - 1s 983us/step - loss: 0.2310 - accuracy: 0.9011\n",
      "Epoch 55/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2296 - accuracy: 0.9048\n",
      "Epoch 56/150\n",
      "717/717 [==============================] - 1s 937us/step - loss: 0.2452 - accuracy: 0.8999\n",
      "Epoch 57/150\n",
      "717/717 [==============================] - 1s 915us/step - loss: 0.2464 - accuracy: 0.8992\n",
      "Epoch 58/150\n",
      "717/717 [==============================] - 1s 953us/step - loss: 0.2323 - accuracy: 0.9091\n",
      "Epoch 59/150\n",
      "717/717 [==============================] - 1s 926us/step - loss: 0.2329 - accuracy: 0.9016\n",
      "Epoch 60/150\n",
      "717/717 [==============================] - 1s 950us/step - loss: 0.2401 - accuracy: 0.9057\n",
      "Epoch 61/150\n",
      "717/717 [==============================] - 1s 989us/step - loss: 0.2374 - accuracy: 0.9003\n",
      "Epoch 62/150\n",
      "717/717 [==============================] - 1s 976us/step - loss: 0.2448 - accuracy: 0.8995\n",
      "Epoch 63/150\n",
      "717/717 [==============================] - 1s 980us/step - loss: 0.2298 - accuracy: 0.9062\n",
      "Epoch 64/150\n",
      "717/717 [==============================] - 1s 992us/step - loss: 0.2367 - accuracy: 0.9057\n",
      "Epoch 65/150\n",
      "717/717 [==============================] - 1s 977us/step - loss: 0.2314 - accuracy: 0.9053\n",
      "Epoch 66/150\n",
      "717/717 [==============================] - 1s 971us/step - loss: 0.2372 - accuracy: 0.8998\n",
      "Epoch 67/150\n",
      "717/717 [==============================] - 1s 991us/step - loss: 0.2408 - accuracy: 0.9020\n",
      "Epoch 68/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.9011\n",
      "Epoch 69/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2311 - accuracy: 0.9096\n",
      "Epoch 70/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2293 - accuracy: 0.9028\n",
      "Epoch 71/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2415 - accuracy: 0.9015\n",
      "Epoch 72/150\n",
      "717/717 [==============================] - 1s 986us/step - loss: 0.2346 - accuracy: 0.9042\n",
      "Epoch 73/150\n",
      "717/717 [==============================] - 1s 995us/step - loss: 0.2223 - accuracy: 0.9104\n",
      "Epoch 74/150\n",
      "717/717 [==============================] - 1s 977us/step - loss: 0.2314 - accuracy: 0.9092\n",
      "Epoch 75/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2317 - accuracy: 0.9034\n",
      "Epoch 76/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2215 - accuracy: 0.9082\n",
      "Epoch 77/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2306 - accuracy: 0.9050\n",
      "Epoch 78/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2236 - accuracy: 0.9064\n",
      "Epoch 79/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2287 - accuracy: 0.9105\n",
      "Epoch 80/150\n",
      "717/717 [==============================] - 1s 982us/step - loss: 0.2255 - accuracy: 0.9073\n",
      "Epoch 81/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2281 - accuracy: 0.9071\n",
      "Epoch 82/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2255 - accuracy: 0.9083\n",
      "Epoch 83/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2341 - accuracy: 0.9035\n",
      "Epoch 84/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2235 - accuracy: 0.9099\n",
      "Epoch 85/150\n",
      "717/717 [==============================] - 1s 992us/step - loss: 0.2369 - accuracy: 0.9011\n",
      "Epoch 86/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2243 - accuracy: 0.9090\n",
      "Epoch 87/150\n",
      "717/717 [==============================] - 1s 981us/step - loss: 0.2274 - accuracy: 0.9030\n",
      "Epoch 88/150\n",
      "717/717 [==============================] - 1s 971us/step - loss: 0.2229 - accuracy: 0.9097\n",
      "Epoch 89/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2301 - accuracy: 0.9091\n",
      "Epoch 90/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2308 - accuracy: 0.9067\n",
      "Epoch 91/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2218 - accuracy: 0.9118\n",
      "Epoch 92/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2234 - accuracy: 0.9066\n",
      "Epoch 93/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2173 - accuracy: 0.9124\n",
      "Epoch 94/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2185 - accuracy: 0.9087\n",
      "Epoch 95/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2276 - accuracy: 0.9055\n",
      "Epoch 96/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2175 - accuracy: 0.9131: 0s - los\n",
      "Epoch 97/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.9070\n",
      "Epoch 98/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2102 - accuracy: 0.9148\n",
      "Epoch 99/150\n",
      "717/717 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.91 - 1s 977us/step - loss: 0.2157 - accuracy: 0.9142\n",
      "Epoch 100/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2154 - accuracy: 0.9110\n",
      "Epoch 101/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2129 - accuracy: 0.9112\n",
      "Epoch 102/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2143 - accuracy: 0.9160\n",
      "Epoch 103/150\n",
      "717/717 [==============================] - 1s 999us/step - loss: 0.2006 - accuracy: 0.9175\n",
      "Epoch 104/150\n",
      "717/717 [==============================] - 1s 991us/step - loss: 0.2172 - accuracy: 0.9119\n",
      "Epoch 105/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2179 - accuracy: 0.9114\n",
      "Epoch 106/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2047 - accuracy: 0.9157\n",
      "Epoch 107/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2133 - accuracy: 0.9103\n",
      "Epoch 108/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2128 - accuracy: 0.9099\n",
      "Epoch 109/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2077 - accuracy: 0.9132\n",
      "Epoch 110/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.9154\n",
      "Epoch 111/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2048 - accuracy: 0.9192\n",
      "Epoch 112/150\n",
      "717/717 [==============================] - 1s 963us/step - loss: 0.2102 - accuracy: 0.9151\n",
      "Epoch 113/150\n",
      "717/717 [==============================] - 1s 959us/step - loss: 0.2065 - accuracy: 0.9185\n",
      "Epoch 114/150\n",
      "717/717 [==============================] - 1s 963us/step - loss: 0.2171 - accuracy: 0.9116\n",
      "Epoch 115/150\n",
      "717/717 [==============================] - 1s 961us/step - loss: 0.2100 - accuracy: 0.91570s - loss: 0.2076 \n",
      "Epoch 116/150\n",
      "717/717 [==============================] - 1s 965us/step - loss: 0.2145 - accuracy: 0.9102\n",
      "Epoch 117/150\n",
      "717/717 [==============================] - 1s 955us/step - loss: 0.2181 - accuracy: 0.9109\n",
      "Epoch 118/150\n",
      "717/717 [==============================] - 1s 958us/step - loss: 0.2125 - accuracy: 0.9118\n",
      "Epoch 119/150\n",
      "717/717 [==============================] - 1s 970us/step - loss: 0.2122 - accuracy: 0.9143\n",
      "Epoch 120/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2091 - accuracy: 0.9179\n",
      "Epoch 121/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2088 - accuracy: 0.9121\n",
      "Epoch 122/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2115 - accuracy: 0.9112\n",
      "Epoch 123/150\n",
      "717/717 [==============================] - 1s 898us/step - loss: 0.2018 - accuracy: 0.9181\n",
      "Epoch 124/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2132 - accuracy: 0.9178\n",
      "Epoch 125/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2130 - accuracy: 0.9124\n",
      "Epoch 126/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2012 - accuracy: 0.9226\n",
      "Epoch 127/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2045 - accuracy: 0.9165\n",
      "Epoch 128/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2180 - accuracy: 0.9111\n",
      "Epoch 129/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2067 - accuracy: 0.9149\n",
      "Epoch 130/150\n",
      "717/717 [==============================] - 1s 873us/step - loss: 0.2098 - accuracy: 0.9133\n",
      "Epoch 131/150\n",
      "717/717 [==============================] - 1s 907us/step - loss: 0.2047 - accuracy: 0.9181\n",
      "Epoch 132/150\n",
      "717/717 [==============================] - 1s 813us/step - loss: 0.1985 - accuracy: 0.9214\n",
      "Epoch 133/150\n",
      "717/717 [==============================] - 1s 915us/step - loss: 0.2022 - accuracy: 0.9183\n",
      "Epoch 134/150\n",
      "717/717 [==============================] - 1s 961us/step - loss: 0.2100 - accuracy: 0.9143\n",
      "Epoch 135/150\n",
      "717/717 [==============================] - 1s 969us/step - loss: 0.1972 - accuracy: 0.9203\n",
      "Epoch 136/150\n",
      "717/717 [==============================] - 1s 957us/step - loss: 0.1943 - accuracy: 0.9212\n",
      "Epoch 137/150\n",
      "717/717 [==============================] - 1s 873us/step - loss: 0.2137 - accuracy: 0.9074\n",
      "Epoch 138/150\n",
      "717/717 [==============================] - 1s 825us/step - loss: 0.2052 - accuracy: 0.9182\n",
      "Epoch 139/150\n",
      "717/717 [==============================] - 1s 898us/step - loss: 0.2069 - accuracy: 0.9145\n",
      "Epoch 140/150\n",
      "717/717 [==============================] - 1s 894us/step - loss: 0.2010 - accuracy: 0.9171\n",
      "Epoch 141/150\n",
      "717/717 [==============================] - 1s 913us/step - loss: 0.2046 - accuracy: 0.9188\n",
      "Epoch 142/150\n",
      "717/717 [==============================] - 1s 943us/step - loss: 0.2145 - accuracy: 0.91300s - loss: 0.2153 - accuracy: 0.\n",
      "Epoch 143/150\n",
      "717/717 [==============================] - 1s 944us/step - loss: 0.1987 - accuracy: 0.9185\n",
      "Epoch 144/150\n",
      "717/717 [==============================] - 1s 906us/step - loss: 0.1979 - accuracy: 0.91640s - loss: 0.1947 - \n",
      "Epoch 145/150\n",
      "717/717 [==============================] - 1s 979us/step - loss: 0.1965 - accuracy: 0.9212\n",
      "Epoch 146/150\n",
      "717/717 [==============================] - 1s 949us/step - loss: 0.2017 - accuracy: 0.9188\n",
      "Epoch 147/150\n",
      "717/717 [==============================] - 1s 909us/step - loss: 0.2103 - accuracy: 0.9143\n",
      "Epoch 148/150\n",
      "717/717 [==============================] - 1s 947us/step - loss: 0.2032 - accuracy: 0.9161\n",
      "Epoch 149/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1904 - accuracy: 0.9266\n",
      "Epoch 150/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2058 - accuracy: 0.9169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23269e9df40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "destroyed-minutes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 708us/step - loss: 0.1920 - accuracy: 0.9231\n",
      "Training accuracy: 92.31\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Training accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effective-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 802us/step - loss: 0.7874 - accuracy: 0.8303\n",
      "Test accuracy: 83.03\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "geographic-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1383,  128],\n",
       "       [ 176,  104]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-anxiety",
   "metadata": {},
   "source": [
    "A batch as a for-loop iterating over one or more samples and making predictions. At the end of the batch, the predictions are compared to the expected output variables and an error is calculated. From this error, the update algorithm is used to improve the model, e.g. move down along the error gradient.  \n",
    "**It has been observed in practice that when using a larger batch there is a significant degradation in the quality of the model, as measured by its ability to generalize.**  \n",
    "The lack of generalization ability is due to the fact that large-batch methods tend to converge to sharp minimizers of the training function.  \n",
    "The number of epochs is the number of complete passes through the training dataset.  \n",
    "Let's try another epoch and batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "invalid-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "224/224 [==============================] - 1s 960us/step - loss: 0.5852 - accuracy: 0.6621\n",
      "Epoch 2/150\n",
      "224/224 [==============================] - 0s 967us/step - loss: 0.3984 - accuracy: 0.8279\n",
      "Epoch 3/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8497\n",
      "Epoch 4/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8558\n",
      "Epoch 5/150\n",
      "224/224 [==============================] - 0s 984us/step - loss: 0.3455 - accuracy: 0.8644\n",
      "Epoch 6/150\n",
      "224/224 [==============================] - 0s 863us/step - loss: 0.3394 - accuracy: 0.8651\n",
      "Epoch 7/150\n",
      "224/224 [==============================] - 0s 959us/step - loss: 0.3353 - accuracy: 0.8679\n",
      "Epoch 8/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8658\n",
      "Epoch 9/150\n",
      "224/224 [==============================] - 0s 975us/step - loss: 0.3356 - accuracy: 0.8645\n",
      "Epoch 10/150\n",
      "224/224 [==============================] - 0s 971us/step - loss: 0.3443 - accuracy: 0.8586\n",
      "Epoch 11/150\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8644\n",
      "Epoch 12/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8708\n",
      "Epoch 13/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8704\n",
      "Epoch 14/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8744\n",
      "Epoch 15/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8747\n",
      "Epoch 16/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8719\n",
      "Epoch 17/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8705\n",
      "Epoch 18/150\n",
      "224/224 [==============================] - 0s 987us/step - loss: 0.3127 - accuracy: 0.8728\n",
      "Epoch 19/150\n",
      "224/224 [==============================] - 0s 962us/step - loss: 0.3094 - accuracy: 0.8755\n",
      "Epoch 20/150\n",
      "224/224 [==============================] - 0s 969us/step - loss: 0.3094 - accuracy: 0.8772\n",
      "Epoch 21/150\n",
      "224/224 [==============================] - 0s 870us/step - loss: 0.2955 - accuracy: 0.8779\n",
      "Epoch 22/150\n",
      "224/224 [==============================] - 0s 938us/step - loss: 0.2959 - accuracy: 0.8803\n",
      "Epoch 23/150\n",
      "224/224 [==============================] - 0s 968us/step - loss: 0.3010 - accuracy: 0.8790\n",
      "Epoch 24/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.8781\n",
      "Epoch 25/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8811\n",
      "Epoch 26/150\n",
      "224/224 [==============================] - 0s 937us/step - loss: 0.3031 - accuracy: 0.8791\n",
      "Epoch 27/150\n",
      "224/224 [==============================] - 0s 976us/step - loss: 0.2888 - accuracy: 0.8837\n",
      "Epoch 28/150\n",
      "224/224 [==============================] - 0s 992us/step - loss: 0.2898 - accuracy: 0.8843\n",
      "Epoch 29/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8856\n",
      "Epoch 30/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8823\n",
      "Epoch 31/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8862\n",
      "Epoch 32/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2726 - accuracy: 0.8885\n",
      "Epoch 33/150\n",
      "224/224 [==============================] - 0s 989us/step - loss: 0.2850 - accuracy: 0.8797\n",
      "Epoch 34/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2747 - accuracy: 0.8902\n",
      "Epoch 35/150\n",
      "224/224 [==============================] - 0s 996us/step - loss: 0.2832 - accuracy: 0.8842\n",
      "Epoch 36/150\n",
      "224/224 [==============================] - 0s 981us/step - loss: 0.2684 - accuracy: 0.8892\n",
      "Epoch 37/150\n",
      "224/224 [==============================] - 0s 980us/step - loss: 0.2716 - accuracy: 0.8856\n",
      "Epoch 38/150\n",
      "224/224 [==============================] - 0s 997us/step - loss: 0.2698 - accuracy: 0.8912\n",
      "Epoch 39/150\n",
      "224/224 [==============================] - 0s 998us/step - loss: 0.2693 - accuracy: 0.8962\n",
      "Epoch 40/150\n",
      "224/224 [==============================] - 0s 985us/step - loss: 0.2726 - accuracy: 0.8892\n",
      "Epoch 41/150\n",
      "224/224 [==============================] - 0s 985us/step - loss: 0.2585 - accuracy: 0.8987\n",
      "Epoch 42/150\n",
      "224/224 [==============================] - 0s 942us/step - loss: 0.2661 - accuracy: 0.8910\n",
      "Epoch 43/150\n",
      "224/224 [==============================] - 0s 1000us/step - loss: 0.2689 - accuracy: 0.8927\n",
      "Epoch 44/150\n",
      "224/224 [==============================] - 0s 944us/step - loss: 0.2707 - accuracy: 0.8895\n",
      "Epoch 45/150\n",
      "224/224 [==============================] - 0s 994us/step - loss: 0.2613 - accuracy: 0.8938\n",
      "Epoch 46/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.8980\n",
      "Epoch 47/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8931\n",
      "Epoch 48/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8994\n",
      "Epoch 49/150\n",
      "224/224 [==============================] - 0s 975us/step - loss: 0.2631 - accuracy: 0.8948\n",
      "Epoch 50/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.8918\n",
      "Epoch 51/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.8902\n",
      "Epoch 52/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8958\n",
      "Epoch 53/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.8936\n",
      "Epoch 54/150\n",
      "224/224 [==============================] - 0s 989us/step - loss: 0.2598 - accuracy: 0.8958\n",
      "Epoch 55/150\n",
      "224/224 [==============================] - 0s 987us/step - loss: 0.2577 - accuracy: 0.8949\n",
      "Epoch 56/150\n",
      "224/224 [==============================] - 0s 876us/step - loss: 0.2531 - accuracy: 0.8977\n",
      "Epoch 57/150\n",
      "224/224 [==============================] - 0s 947us/step - loss: 0.2586 - accuracy: 0.89530s - loss: 0.2562 - accuracy\n",
      "Epoch 58/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.8983\n",
      "Epoch 59/150\n",
      "224/224 [==============================] - 0s 721us/step - loss: 0.2500 - accuracy: 0.9001\n",
      "Epoch 60/150\n",
      "224/224 [==============================] - 0s 763us/step - loss: 0.2490 - accuracy: 0.8976\n",
      "Epoch 61/150\n",
      "224/224 [==============================] - 0s 971us/step - loss: 0.2665 - accuracy: 0.8877\n",
      "Epoch 62/150\n",
      "224/224 [==============================] - 0s 853us/step - loss: 0.2417 - accuracy: 0.9053\n",
      "Epoch 63/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.8983\n",
      "Epoch 64/150\n",
      "224/224 [==============================] - 0s 944us/step - loss: 0.2524 - accuracy: 0.9010\n",
      "Epoch 65/150\n",
      "224/224 [==============================] - 0s 820us/step - loss: 0.2453 - accuracy: 0.8998\n",
      "Epoch 66/150\n",
      "224/224 [==============================] - 0s 807us/step - loss: 0.2440 - accuracy: 0.9061\n",
      "Epoch 67/150\n",
      "224/224 [==============================] - 0s 932us/step - loss: 0.2485 - accuracy: 0.8937\n",
      "Epoch 68/150\n",
      "224/224 [==============================] - 0s 934us/step - loss: 0.2482 - accuracy: 0.9041\n",
      "Epoch 69/150\n",
      "224/224 [==============================] - 0s 807us/step - loss: 0.2479 - accuracy: 0.9031\n",
      "Epoch 70/150\n",
      "224/224 [==============================] - 0s 886us/step - loss: 0.2333 - accuracy: 0.9102\n",
      "Epoch 71/150\n",
      "224/224 [==============================] - 0s 986us/step - loss: 0.2419 - accuracy: 0.9062\n",
      "Epoch 72/150\n",
      "224/224 [==============================] - 0s 863us/step - loss: 0.2507 - accuracy: 0.8985\n",
      "Epoch 73/150\n",
      "224/224 [==============================] - 0s 758us/step - loss: 0.2413 - accuracy: 0.9056\n",
      "Epoch 74/150\n",
      "224/224 [==============================] - 0s 824us/step - loss: 0.2409 - accuracy: 0.8997\n",
      "Epoch 75/150\n",
      "224/224 [==============================] - 0s 920us/step - loss: 0.2508 - accuracy: 0.8996\n",
      "Epoch 76/150\n",
      "224/224 [==============================] - 0s 949us/step - loss: 0.2541 - accuracy: 0.9049\n",
      "Epoch 77/150\n",
      "224/224 [==============================] - 0s 943us/step - loss: 0.2486 - accuracy: 0.9012\n",
      "Epoch 78/150\n",
      "224/224 [==============================] - 0s 978us/step - loss: 0.2480 - accuracy: 0.8977\n",
      "Epoch 79/150\n",
      "224/224 [==============================] - 0s 999us/step - loss: 0.2410 - accuracy: 0.9069\n",
      "Epoch 80/150\n",
      "224/224 [==============================] - 0s 764us/step - loss: 0.2456 - accuracy: 0.9042\n",
      "Epoch 81/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.9048\n",
      "Epoch 82/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.9018\n",
      "Epoch 83/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9062\n",
      "Epoch 84/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9091: 0s - loss: 0.2335 - accura\n",
      "Epoch 85/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9100\n",
      "Epoch 86/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9043\n",
      "Epoch 87/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9115\n",
      "Epoch 88/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9081\n",
      "Epoch 89/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9054\n",
      "Epoch 90/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9033\n",
      "Epoch 91/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9088\n",
      "Epoch 92/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.8976\n",
      "Epoch 93/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9074\n",
      "Epoch 94/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.9048\n",
      "Epoch 95/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9129\n",
      "Epoch 96/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9125\n",
      "Epoch 97/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9076\n",
      "Epoch 98/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9138\n",
      "Epoch 99/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9060\n",
      "Epoch 100/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9073\n",
      "Epoch 101/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9073\n",
      "Epoch 102/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9118\n",
      "Epoch 103/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9117\n",
      "Epoch 104/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9160\n",
      "Epoch 105/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9108\n",
      "Epoch 106/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9092\n",
      "Epoch 107/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9100\n",
      "Epoch 108/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9108\n",
      "Epoch 109/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9044\n",
      "Epoch 110/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9130\n",
      "Epoch 111/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9081\n",
      "Epoch 112/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9104\n",
      "Epoch 113/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9161\n",
      "Epoch 114/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9089\n",
      "Epoch 115/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9108\n",
      "Epoch 116/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9079\n",
      "Epoch 117/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9048\n",
      "Epoch 118/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9170\n",
      "Epoch 119/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9151\n",
      "Epoch 120/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9123\n",
      "Epoch 121/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9106\n",
      "Epoch 122/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9125\n",
      "Epoch 123/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9093\n",
      "Epoch 124/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9098\n",
      "Epoch 125/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9126\n",
      "Epoch 126/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9103\n",
      "Epoch 127/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9123\n",
      "Epoch 128/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9148\n",
      "Epoch 129/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9094\n",
      "Epoch 130/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9142\n",
      "Epoch 131/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9149\n",
      "Epoch 132/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9132\n",
      "Epoch 133/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9166\n",
      "Epoch 134/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9140\n",
      "Epoch 135/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9160\n",
      "Epoch 136/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9122\n",
      "Epoch 137/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9101\n",
      "Epoch 138/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9111\n",
      "Epoch 139/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.9093\n",
      "Epoch 140/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9091\n",
      "Epoch 141/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9120\n",
      "Epoch 142/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9114\n",
      "Epoch 143/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9133\n",
      "Epoch 144/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2097 - accuracy: 0.9151\n",
      "Epoch 145/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.9169\n",
      "Epoch 146/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9195\n",
      "Epoch 147/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9127\n",
      "Epoch 148/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9138\n",
      "Epoch 149/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.9134\n",
      "Epoch 150/150\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12d423650d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "italic-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 675us/step - loss: 0.2103 - accuracy: 0.9160\n",
      "Training accuracy: 91.60\n",
      "56/56 [==============================] - 0s 766us/step - loss: 0.5978 - accuracy: 0.8264\n",
      "Test accuracy: 82.64\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Training accuracy: %.2f' % (accuracy*100))\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "registered-performance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "224/224 [==============================] - 0s 973us/step - loss: 0.2189 - accuracy: 0.9121\n",
      "Epoch 2/300\n",
      "224/224 [==============================] - 0s 980us/step - loss: 0.2195 - accuracy: 0.9137\n",
      "Epoch 3/300\n",
      "224/224 [==============================] - 0s 958us/step - loss: 0.2180 - accuracy: 0.9111\n",
      "Epoch 4/300\n",
      "224/224 [==============================] - 0s 987us/step - loss: 0.2176 - accuracy: 0.9151\n",
      "Epoch 5/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9122\n",
      "Epoch 6/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9151\n",
      "Epoch 7/300\n",
      "224/224 [==============================] - 0s 957us/step - loss: 0.2178 - accuracy: 0.9128\n",
      "Epoch 8/300\n",
      "224/224 [==============================] - 0s 938us/step - loss: 0.2184 - accuracy: 0.9142\n",
      "Epoch 9/300\n",
      "224/224 [==============================] - 0s 931us/step - loss: 0.2175 - accuracy: 0.9139\n",
      "Epoch 10/300\n",
      "224/224 [==============================] - 0s 966us/step - loss: 0.2157 - accuracy: 0.9150\n",
      "Epoch 11/300\n",
      "224/224 [==============================] - 0s 941us/step - loss: 0.2173 - accuracy: 0.9122\n",
      "Epoch 12/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9161\n",
      "Epoch 13/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9144\n",
      "Epoch 14/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9139\n",
      "Epoch 15/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9150\n",
      "Epoch 16/300\n",
      "224/224 [==============================] - 0s 979us/step - loss: 0.2153 - accuracy: 0.9161\n",
      "Epoch 17/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9146\n",
      "Epoch 18/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.9143\n",
      "Epoch 19/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2160 - accuracy: 0.9161\n",
      "Epoch 20/300\n",
      "224/224 [==============================] - 0s 883us/step - loss: 0.2150 - accuracy: 0.9162\n",
      "Epoch 21/300\n",
      "224/224 [==============================] - 0s 998us/step - loss: 0.2148 - accuracy: 0.9160\n",
      "Epoch 22/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9162\n",
      "Epoch 23/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9164\n",
      "Epoch 24/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9158\n",
      "Epoch 25/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9160\n",
      "Epoch 26/300\n",
      "224/224 [==============================] - 0s 943us/step - loss: 0.2132 - accuracy: 0.9160\n",
      "Epoch 27/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.9168\n",
      "Epoch 28/300\n",
      "224/224 [==============================] - 0s 988us/step - loss: 0.2128 - accuracy: 0.9140\n",
      "Epoch 29/300\n",
      "224/224 [==============================] - 0s 990us/step - loss: 0.2119 - accuracy: 0.9161\n",
      "Epoch 30/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9175\n",
      "Epoch 31/300\n",
      "224/224 [==============================] - 0s 991us/step - loss: 0.2118 - accuracy: 0.9164\n",
      "Epoch 32/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9155\n",
      "Epoch 33/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9169\n",
      "Epoch 34/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.9158\n",
      "Epoch 35/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.9169\n",
      "Epoch 36/300\n",
      "224/224 [==============================] - 0s 896us/step - loss: 0.2114 - accuracy: 0.9160\n",
      "Epoch 37/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9185\n",
      "Epoch 38/300\n",
      "224/224 [==============================] - 0s 996us/step - loss: 0.2104 - accuracy: 0.9172\n",
      "Epoch 39/300\n",
      "224/224 [==============================] - 0s 975us/step - loss: 0.2094 - accuracy: 0.9178\n",
      "Epoch 40/300\n",
      "224/224 [==============================] - 0s 946us/step - loss: 0.2104 - accuracy: 0.9162\n",
      "Epoch 41/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.9149\n",
      "Epoch 42/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9158\n",
      "Epoch 43/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9176\n",
      "Epoch 44/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9181\n",
      "Epoch 45/300\n",
      "224/224 [==============================] - 0s 980us/step - loss: 0.2080 - accuracy: 0.9186\n",
      "Epoch 46/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9211\n",
      "Epoch 47/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.9185\n",
      "Epoch 48/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9165\n",
      "Epoch 49/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.9154\n",
      "Epoch 50/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9168\n",
      "Epoch 51/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.9162\n",
      "Epoch 52/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9172\n",
      "Epoch 53/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9174\n",
      "Epoch 54/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.9188\n",
      "Epoch 55/300\n",
      "224/224 [==============================] - 0s 984us/step - loss: 0.2061 - accuracy: 0.9195\n",
      "Epoch 56/300\n",
      "224/224 [==============================] - 0s 979us/step - loss: 0.2072 - accuracy: 0.9176\n",
      "Epoch 57/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9200\n",
      "Epoch 58/300\n",
      "224/224 [==============================] - 0s 962us/step - loss: 0.2062 - accuracy: 0.9190\n",
      "Epoch 59/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9189\n",
      "Epoch 60/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9176\n",
      "Epoch 61/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.9209\n",
      "Epoch 62/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.9192\n",
      "Epoch 63/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.9188\n",
      "Epoch 64/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.9199\n",
      "Epoch 65/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9202\n",
      "Epoch 66/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9207\n",
      "Epoch 67/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9204\n",
      "Epoch 68/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9195: 0s - loss: 0.2038 - accuracy: 0.92\n",
      "Epoch 69/300\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.92 - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9214\n",
      "Epoch 70/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9206\n",
      "Epoch 71/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9190\n",
      "Epoch 72/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9196\n",
      "Epoch 73/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9218\n",
      "Epoch 74/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9206\n",
      "Epoch 75/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9199\n",
      "Epoch 76/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2039 - accuracy: 0.9211\n",
      "Epoch 77/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2039 - accuracy: 0.9220\n",
      "Epoch 78/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9218\n",
      "Epoch 79/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.9197\n",
      "Epoch 80/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.9214\n",
      "Epoch 81/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.9214\n",
      "Epoch 82/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9211\n",
      "Epoch 83/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9223\n",
      "Epoch 84/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9216\n",
      "Epoch 85/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9214\n",
      "Epoch 86/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9210\n",
      "Epoch 87/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9195\n",
      "Epoch 88/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9202\n",
      "Epoch 89/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9218\n",
      "Epoch 90/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9206\n",
      "Epoch 91/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9217\n",
      "Epoch 92/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9228\n",
      "Epoch 93/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9229\n",
      "Epoch 94/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9210\n",
      "Epoch 95/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9224\n",
      "Epoch 96/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9211\n",
      "Epoch 97/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9217\n",
      "Epoch 98/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9223\n",
      "Epoch 99/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9232\n",
      "Epoch 100/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9228\n",
      "Epoch 101/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9227\n",
      "Epoch 102/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9210\n",
      "Epoch 103/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9228\n",
      "Epoch 104/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9227\n",
      "Epoch 105/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9232\n",
      "Epoch 106/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9228\n",
      "Epoch 107/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9236\n",
      "Epoch 108/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9218\n",
      "Epoch 109/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9234\n",
      "Epoch 110/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9225\n",
      "Epoch 111/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9238\n",
      "Epoch 112/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9224\n",
      "Epoch 113/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9227\n",
      "Epoch 114/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9229\n",
      "Epoch 115/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9236\n",
      "Epoch 116/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9245\n",
      "Epoch 117/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9243\n",
      "Epoch 118/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9235\n",
      "Epoch 119/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9245\n",
      "Epoch 120/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9227\n",
      "Epoch 121/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9239\n",
      "Epoch 122/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9246\n",
      "Epoch 123/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9245\n",
      "Epoch 124/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9229\n",
      "Epoch 125/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9225\n",
      "Epoch 126/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9242\n",
      "Epoch 127/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9225\n",
      "Epoch 128/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9239\n",
      "Epoch 129/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9225\n",
      "Epoch 130/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9249\n",
      "Epoch 131/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9241\n",
      "Epoch 132/300\n",
      "224/224 [==============================] - 0s 899us/step - loss: 0.1954 - accuracy: 0.9242\n",
      "Epoch 133/300\n",
      "224/224 [==============================] - 0s 975us/step - loss: 0.1955 - accuracy: 0.9235\n",
      "Epoch 134/300\n",
      "224/224 [==============================] - 0s 922us/step - loss: 0.1949 - accuracy: 0.9239\n",
      "Epoch 135/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9245\n",
      "Epoch 136/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9229\n",
      "Epoch 137/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9256\n",
      "Epoch 138/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9235\n",
      "Epoch 139/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.9220\n",
      "Epoch 140/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9238\n",
      "Epoch 141/300\n",
      "224/224 [==============================] - 0s 983us/step - loss: 0.1951 - accuracy: 0.9221\n",
      "Epoch 142/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9252\n",
      "Epoch 143/300\n",
      "224/224 [==============================] - 0s 997us/step - loss: 0.1936 - accuracy: 0.9249\n",
      "Epoch 144/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9256\n",
      "Epoch 145/300\n",
      "224/224 [==============================] - 0s 995us/step - loss: 0.1937 - accuracy: 0.9227\n",
      "Epoch 146/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9221\n",
      "Epoch 147/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.9248\n",
      "Epoch 148/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9218\n",
      "Epoch 149/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9246\n",
      "Epoch 150/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.9257\n",
      "Epoch 151/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9239\n",
      "Epoch 152/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9223\n",
      "Epoch 153/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9235\n",
      "Epoch 154/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9241\n",
      "Epoch 155/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9255\n",
      "Epoch 156/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9248\n",
      "Epoch 157/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9243\n",
      "Epoch 158/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9253\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9249\n",
      "Epoch 160/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9266\n",
      "Epoch 161/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9246\n",
      "Epoch 162/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9236\n",
      "Epoch 163/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9229\n",
      "Epoch 164/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9225\n",
      "Epoch 165/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9242\n",
      "Epoch 166/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9262\n",
      "Epoch 167/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9255\n",
      "Epoch 168/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9228\n",
      "Epoch 169/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9239\n",
      "Epoch 170/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9248\n",
      "Epoch 171/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9243\n",
      "Epoch 172/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9243\n",
      "Epoch 173/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9260\n",
      "Epoch 174/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9253\n",
      "Epoch 175/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9255\n",
      "Epoch 176/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9227\n",
      "Epoch 177/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9269\n",
      "Epoch 178/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.9257\n",
      "Epoch 179/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9256\n",
      "Epoch 180/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9223\n",
      "Epoch 181/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9252\n",
      "Epoch 182/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9241\n",
      "Epoch 183/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.9257\n",
      "Epoch 184/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9242\n",
      "Epoch 185/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9255\n",
      "Epoch 186/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9259\n",
      "Epoch 187/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9255\n",
      "Epoch 188/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9281\n",
      "Epoch 189/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9264\n",
      "Epoch 190/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9245\n",
      "Epoch 191/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9243\n",
      "Epoch 192/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9267\n",
      "Epoch 193/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9242\n",
      "Epoch 194/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9262\n",
      "Epoch 195/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.9266\n",
      "Epoch 196/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9269\n",
      "Epoch 197/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9253\n",
      "Epoch 198/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9269\n",
      "Epoch 199/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9266\n",
      "Epoch 200/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9266\n",
      "Epoch 201/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9259\n",
      "Epoch 202/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9235\n",
      "Epoch 203/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9277\n",
      "Epoch 204/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9269\n",
      "Epoch 205/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9264\n",
      "Epoch 206/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9252\n",
      "Epoch 207/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9235\n",
      "Epoch 208/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9264\n",
      "Epoch 209/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.9277\n",
      "Epoch 210/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9249\n",
      "Epoch 211/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9267\n",
      "Epoch 212/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9262\n",
      "Epoch 213/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9292\n",
      "Epoch 214/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.9243\n",
      "Epoch 215/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9259\n",
      "Epoch 216/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9283\n",
      "Epoch 217/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9264\n",
      "Epoch 218/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9263\n",
      "Epoch 219/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9278\n",
      "Epoch 220/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9264\n",
      "Epoch 221/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9253\n",
      "Epoch 222/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9266\n",
      "Epoch 223/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.9252\n",
      "Epoch 224/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9267\n",
      "Epoch 225/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9262\n",
      "Epoch 226/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9267\n",
      "Epoch 227/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9252\n",
      "Epoch 228/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9250\n",
      "Epoch 229/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9280\n",
      "Epoch 230/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9269\n",
      "Epoch 231/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9253\n",
      "Epoch 232/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9263\n",
      "Epoch 233/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9284\n",
      "Epoch 234/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9252\n",
      "Epoch 235/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9274\n",
      "Epoch 236/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9262\n",
      "Epoch 237/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9266\n",
      "Epoch 238/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9269\n",
      "Epoch 239/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.9284\n",
      "Epoch 240/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.9269\n",
      "Epoch 241/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9276\n",
      "Epoch 242/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9263\n",
      "Epoch 243/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9269\n",
      "Epoch 244/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9256\n",
      "Epoch 245/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9287\n",
      "Epoch 246/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9278\n",
      "Epoch 247/300\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.92 - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9250\n",
      "Epoch 248/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9278\n",
      "Epoch 249/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9269\n",
      "Epoch 250/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9266\n",
      "Epoch 251/300\n",
      "224/224 [==============================] - 0s 964us/step - loss: 0.1855 - accuracy: 0.9267\n",
      "Epoch 252/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9253\n",
      "Epoch 253/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9277\n",
      "Epoch 254/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9277\n",
      "Epoch 255/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9266\n",
      "Epoch 256/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9267\n",
      "Epoch 257/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9277\n",
      "Epoch 258/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9276\n",
      "Epoch 259/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9281\n",
      "Epoch 260/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9262\n",
      "Epoch 261/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9285\n",
      "Epoch 262/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9255\n",
      "Epoch 263/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9246\n",
      "Epoch 264/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9278: 0s - loss: 0.1798 - accuracy: \n",
      "Epoch 265/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9280\n",
      "Epoch 266/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9273\n",
      "Epoch 267/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9262\n",
      "Epoch 268/300\n",
      "224/224 [==============================] - 0s 992us/step - loss: 0.1836 - accuracy: 0.9284\n",
      "Epoch 269/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9269\n",
      "Epoch 270/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9270\n",
      "Epoch 271/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9266\n",
      "Epoch 272/300\n",
      "224/224 [==============================] - 0s 990us/step - loss: 0.1831 - accuracy: 0.9288\n",
      "Epoch 273/300\n",
      "224/224 [==============================] - 0s 999us/step - loss: 0.1836 - accuracy: 0.9270\n",
      "Epoch 274/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9262\n",
      "Epoch 275/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9290\n",
      "Epoch 276/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9281\n",
      "Epoch 277/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9263\n",
      "Epoch 278/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9259\n",
      "Epoch 279/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9283\n",
      "Epoch 280/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9281\n",
      "Epoch 281/300\n",
      "224/224 [==============================] - 0s 993us/step - loss: 0.1824 - accuracy: 0.9281\n",
      "Epoch 282/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9288\n",
      "Epoch 283/300\n",
      "224/224 [==============================] - 0s 999us/step - loss: 0.1841 - accuracy: 0.9253\n",
      "Epoch 284/300\n",
      "224/224 [==============================] - 0s 986us/step - loss: 0.1821 - accuracy: 0.9294\n",
      "Epoch 285/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9263\n",
      "Epoch 286/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9277\n",
      "Epoch 287/300\n",
      "224/224 [==============================] - 0s 960us/step - loss: 0.1835 - accuracy: 0.9283\n",
      "Epoch 288/300\n",
      "224/224 [==============================] - 0s 991us/step - loss: 0.1824 - accuracy: 0.9263\n",
      "Epoch 289/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9285\n",
      "Epoch 290/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.9267\n",
      "Epoch 291/300\n",
      "224/224 [==============================] - 0s 993us/step - loss: 0.1833 - accuracy: 0.9274\n",
      "Epoch 292/300\n",
      "224/224 [==============================] - 0s 939us/step - loss: 0.1827 - accuracy: 0.9276\n",
      "Epoch 293/300\n",
      "224/224 [==============================] - 0s 944us/step - loss: 0.1819 - accuracy: 0.9291\n",
      "Epoch 294/300\n",
      "224/224 [==============================] - 0s 993us/step - loss: 0.1806 - accuracy: 0.9292\n",
      "Epoch 295/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9278\n",
      "Epoch 296/300\n",
      "224/224 [==============================] - 0s 930us/step - loss: 0.1831 - accuracy: 0.9263\n",
      "Epoch 297/300\n",
      "224/224 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9280\n",
      "Epoch 298/300\n",
      "224/224 [==============================] - 0s 984us/step - loss: 0.1817 - accuracy: 0.9285\n",
      "Epoch 299/300\n",
      "224/224 [==============================] - 0s 993us/step - loss: 0.1824 - accuracy: 0.9280\n",
      "Epoch 300/300\n",
      "224/224 [==============================] - 0s 792us/step - loss: 0.1825 - accuracy: 0.9288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12d485f1f40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "temporal-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 701us/step - loss: 0.1742 - accuracy: 0.9333\n",
      "Training accuracy: 93.33\n",
      "56/56 [==============================] - 0s 751us/step - loss: 0.7956 - accuracy: 0.7973\n",
      "Test accuracy: 79.73\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Training accuracy: %.2f' % (accuracy*100))\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-eleven",
   "metadata": {},
   "source": [
    "Interestingly, higher count of epoch brought worse test set accuracy. Overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-abortion",
   "metadata": {},
   "source": [
    "Now trying other parameters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "different-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense((len(X)+1)/2, input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-inventory",
   "metadata": {},
   "source": [
    "I added one input layer and the number of nodes in that layer is the mean off the nodes in input and output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "emotional-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "excessive-brick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "717/717 [==============================] - 3s 3ms/step - loss: 0.3944 - accuracy: 0.8446\n",
      "Epoch 2/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.3493 - accuracy: 0.8603\n",
      "Epoch 3/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.3483 - accuracy: 0.8617\n",
      "Epoch 4/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.3154 - accuracy: 0.8707\n",
      "Epoch 5/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.2892 - accuracy: 0.8842\n",
      "Epoch 6/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.2588 - accuracy: 0.8955\n",
      "Epoch 7/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.2205 - accuracy: 0.9137\n",
      "Epoch 8/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.2010 - accuracy: 0.9223\n",
      "Epoch 9/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.1792 - accuracy: 0.9334\n",
      "Epoch 10/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.1578 - accuracy: 0.9423\n",
      "Epoch 11/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.1255 - accuracy: 0.9529\n",
      "Epoch 12/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.1226 - accuracy: 0.9536\n",
      "Epoch 13/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.1034 - accuracy: 0.9627\n",
      "Epoch 14/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0920 - accuracy: 0.9660\n",
      "Epoch 15/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0887 - accuracy: 0.9649\n",
      "Epoch 16/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0823 - accuracy: 0.9700\n",
      "Epoch 17/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0771 - accuracy: 0.9692\n",
      "Epoch 18/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0804 - accuracy: 0.9709\n",
      "Epoch 19/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0763 - accuracy: 0.9710\n",
      "Epoch 20/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0680 - accuracy: 0.9739\n",
      "Epoch 21/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0698 - accuracy: 0.9727\n",
      "Epoch 22/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0670 - accuracy: 0.9753\n",
      "Epoch 23/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0701 - accuracy: 0.9723\n",
      "Epoch 24/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0699 - accuracy: 0.9733\n",
      "Epoch 25/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0585 - accuracy: 0.9792\n",
      "Epoch 26/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0593 - accuracy: 0.9748: 0s - loss: 0.0583 - accura\n",
      "Epoch 27/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0580 - accuracy: 0.9762\n",
      "Epoch 28/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0569 - accuracy: 0.9762\n",
      "Epoch 29/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0588 - accuracy: 0.9763\n",
      "Epoch 30/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0647 - accuracy: 0.9738\n",
      "Epoch 31/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0583 - accuracy: 0.9763\n",
      "Epoch 32/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0558 - accuracy: 0.9755\n",
      "Epoch 33/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0526 - accuracy: 0.9769\n",
      "Epoch 34/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0479 - accuracy: 0.9781\n",
      "Epoch 35/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0515 - accuracy: 0.9781\n",
      "Epoch 36/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0527 - accuracy: 0.9777\n",
      "Epoch 37/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0508 - accuracy: 0.9773\n",
      "Epoch 38/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0516 - accuracy: 0.9773\n",
      "Epoch 39/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.9779\n",
      "Epoch 40/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0558 - accuracy: 0.9766\n",
      "Epoch 41/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9757\n",
      "Epoch 42/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.9761\n",
      "Epoch 43/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.9758\n",
      "Epoch 44/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0543 - accuracy: 0.9763\n",
      "Epoch 45/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0453 - accuracy: 0.9805\n",
      "Epoch 46/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0488 - accuracy: 0.9758\n",
      "Epoch 47/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0445 - accuracy: 0.9810\n",
      "Epoch 48/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0462 - accuracy: 0.9789\n",
      "Epoch 49/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0463 - accuracy: 0.9765\n",
      "Epoch 50/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0472 - accuracy: 0.9769\n",
      "Epoch 51/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.9785\n",
      "Epoch 52/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0492 - accuracy: 0.9771\n",
      "Epoch 53/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0407 - accuracy: 0.9837\n",
      "Epoch 54/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0424 - accuracy: 0.9807\n",
      "Epoch 55/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0458 - accuracy: 0.9809\n",
      "Epoch 56/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0406 - accuracy: 0.9809\n",
      "Epoch 57/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0416 - accuracy: 0.9815\n",
      "Epoch 58/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0384 - accuracy: 0.9822\n",
      "Epoch 59/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0438 - accuracy: 0.9821\n",
      "Epoch 60/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0444 - accuracy: 0.9795\n",
      "Epoch 61/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0449 - accuracy: 0.9797\n",
      "Epoch 62/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0436 - accuracy: 0.9815\n",
      "Epoch 63/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0477 - accuracy: 0.9786\n",
      "Epoch 64/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0376 - accuracy: 0.9832\n",
      "Epoch 65/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0465 - accuracy: 0.9782\n",
      "Epoch 66/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0476 - accuracy: 0.9777\n",
      "Epoch 67/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0419 - accuracy: 0.9789\n",
      "Epoch 68/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0415 - accuracy: 0.9816\n",
      "Epoch 69/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0416 - accuracy: 0.9820\n",
      "Epoch 70/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0403 - accuracy: 0.9810\n",
      "Epoch 71/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0438 - accuracy: 0.9817\n",
      "Epoch 72/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0405 - accuracy: 0.9815\n",
      "Epoch 73/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0368 - accuracy: 0.9843\n",
      "Epoch 74/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0452 - accuracy: 0.9789\n",
      "Epoch 75/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0441 - accuracy: 0.9778\n",
      "Epoch 76/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0424 - accuracy: 0.9808\n",
      "Epoch 77/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0391 - accuracy: 0.9812\n",
      "Epoch 78/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0412 - accuracy: 0.9807\n",
      "Epoch 79/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0323 - accuracy: 0.9854\n",
      "Epoch 80/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0374 - accuracy: 0.9835\n",
      "Epoch 81/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0380 - accuracy: 0.9827\n",
      "Epoch 82/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0383 - accuracy: 0.9825\n",
      "Epoch 83/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0348 - accuracy: 0.9820\n",
      "Epoch 84/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0451 - accuracy: 0.9777\n",
      "Epoch 85/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.9815\n",
      "Epoch 86/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0354 - accuracy: 0.9822\n",
      "Epoch 87/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0334 - accuracy: 0.9858\n",
      "Epoch 88/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0371 - accuracy: 0.9820\n",
      "Epoch 89/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0359 - accuracy: 0.9825\n",
      "Epoch 90/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0400 - accuracy: 0.9804\n",
      "Epoch 91/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0360 - accuracy: 0.9848\n",
      "Epoch 92/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0340 - accuracy: 0.9834\n",
      "Epoch 93/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0402 - accuracy: 0.9817\n",
      "Epoch 94/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0369 - accuracy: 0.9821\n",
      "Epoch 95/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0399 - accuracy: 0.9826\n",
      "Epoch 96/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0367 - accuracy: 0.9841\n",
      "Epoch 97/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0360 - accuracy: 0.9832\n",
      "Epoch 98/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0328 - accuracy: 0.9853\n",
      "Epoch 99/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0331 - accuracy: 0.9861\n",
      "Epoch 100/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0350 - accuracy: 0.9836\n",
      "Epoch 101/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0333 - accuracy: 0.9864\n",
      "Epoch 102/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0326 - accuracy: 0.9852\n",
      "Epoch 103/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0321 - accuracy: 0.9860\n",
      "Epoch 104/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0340 - accuracy: 0.9838\n",
      "Epoch 105/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0331 - accuracy: 0.9849\n",
      "Epoch 106/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0331 - accuracy: 0.9854\n",
      "Epoch 107/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0322 - accuracy: 0.9858\n",
      "Epoch 108/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0321 - accuracy: 0.9843\n",
      "Epoch 109/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0330 - accuracy: 0.9845\n",
      "Epoch 110/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0376 - accuracy: 0.9828\n",
      "Epoch 111/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0310 - accuracy: 0.9864\n",
      "Epoch 112/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0319 - accuracy: 0.9855\n",
      "Epoch 113/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0290 - accuracy: 0.9876\n",
      "Epoch 114/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0272 - accuracy: 0.9887\n",
      "Epoch 115/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0280 - accuracy: 0.9864\n",
      "Epoch 116/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0321 - accuracy: 0.9854\n",
      "Epoch 117/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0384 - accuracy: 0.9840\n",
      "Epoch 118/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0261 - accuracy: 0.9865\n",
      "Epoch 119/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0358 - accuracy: 0.9834\n",
      "Epoch 120/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0320 - accuracy: 0.9853\n",
      "Epoch 121/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0329 - accuracy: 0.9849\n",
      "Epoch 122/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0289 - accuracy: 0.9862\n",
      "Epoch 123/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0331 - accuracy: 0.9856\n",
      "Epoch 124/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0347 - accuracy: 0.9845\n",
      "Epoch 125/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0293 - accuracy: 0.9857\n",
      "Epoch 126/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0305 - accuracy: 0.9850\n",
      "Epoch 127/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0368 - accuracy: 0.9828\n",
      "Epoch 128/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0352 - accuracy: 0.9835\n",
      "Epoch 129/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0285 - accuracy: 0.9874\n",
      "Epoch 130/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0294 - accuracy: 0.9859\n",
      "Epoch 131/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0275 - accuracy: 0.9873\n",
      "Epoch 132/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0265 - accuracy: 0.9867\n",
      "Epoch 133/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0284 - accuracy: 0.9869\n",
      "Epoch 134/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0300 - accuracy: 0.9850\n",
      "Epoch 135/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0304 - accuracy: 0.9853\n",
      "Epoch 136/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0291 - accuracy: 0.9853\n",
      "Epoch 137/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0264 - accuracy: 0.9879\n",
      "Epoch 138/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0269 - accuracy: 0.9870\n",
      "Epoch 139/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0261 - accuracy: 0.9877\n",
      "Epoch 140/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0299 - accuracy: 0.9863\n",
      "Epoch 141/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0296 - accuracy: 0.9854\n",
      "Epoch 142/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0274 - accuracy: 0.9868\n",
      "Epoch 143/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0325 - accuracy: 0.9847\n",
      "Epoch 144/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0289 - accuracy: 0.9859\n",
      "Epoch 145/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0277 - accuracy: 0.9872\n",
      "Epoch 146/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0299 - accuracy: 0.9867\n",
      "Epoch 147/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0343 - accuracy: 0.9847\n",
      "Epoch 148/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0305 - accuracy: 0.9857\n",
      "Epoch 149/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0271 - accuracy: 0.9882\n",
      "Epoch 150/150\n",
      "717/717 [==============================] - 2s 3ms/step - loss: 0.0254 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12d48b42d00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "finished-douglas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9895\n",
      "Training accuracy: 98.95\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 2.5462 - accuracy: 0.8135\n",
      "Test accuracy: 81.35\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Training accuracy: %.2f' % (accuracy*100))\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-nomination",
   "metadata": {},
   "source": [
    "Execution was much more slower and test accuracy did not even increase. Overfitting.  \n",
    "Let's try a deeper network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "secondary-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "717/717 [==============================] - 1s 992us/step - loss: 0.4766 - accuracy: 0.8230\n",
      "Epoch 2/150\n",
      "717/717 [==============================] - 1s 967us/step - loss: 0.3624 - accuracy: 0.8584\n",
      "Epoch 3/150\n",
      "717/717 [==============================] - 1s 949us/step - loss: 0.3614 - accuracy: 0.8492\n",
      "Epoch 4/150\n",
      "717/717 [==============================] - 1s 983us/step - loss: 0.3491 - accuracy: 0.8562\n",
      "Epoch 5/150\n",
      "717/717 [==============================] - 1s 995us/step - loss: 0.3475 - accuracy: 0.8578\n",
      "Epoch 6/150\n",
      "717/717 [==============================] - 1s 978us/step - loss: 0.3356 - accuracy: 0.8634\n",
      "Epoch 7/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.8672\n",
      "Epoch 8/150\n",
      "717/717 [==============================] - 1s 980us/step - loss: 0.3297 - accuracy: 0.8711\n",
      "Epoch 9/150\n",
      "717/717 [==============================] - 1s 978us/step - loss: 0.3308 - accuracy: 0.8654\n",
      "Epoch 10/150\n",
      "717/717 [==============================] - 1s 940us/step - loss: 0.3250 - accuracy: 0.8682\n",
      "Epoch 11/150\n",
      "717/717 [==============================] - 1s 962us/step - loss: 0.3142 - accuracy: 0.8761\n",
      "Epoch 12/150\n",
      "717/717 [==============================] - 1s 957us/step - loss: 0.3069 - accuracy: 0.8770\n",
      "Epoch 13/150\n",
      "717/717 [==============================] - 1s 959us/step - loss: 0.3158 - accuracy: 0.8760\n",
      "Epoch 14/150\n",
      "717/717 [==============================] - 1s 993us/step - loss: 0.3105 - accuracy: 0.8783\n",
      "Epoch 15/150\n",
      "717/717 [==============================] - 1s 954us/step - loss: 0.3033 - accuracy: 0.8760\n",
      "Epoch 16/150\n",
      "717/717 [==============================] - 1s 964us/step - loss: 0.3015 - accuracy: 0.8778\n",
      "Epoch 17/150\n",
      "717/717 [==============================] - 1s 968us/step - loss: 0.3047 - accuracy: 0.8778\n",
      "Epoch 18/150\n",
      "717/717 [==============================] - 1s 972us/step - loss: 0.3013 - accuracy: 0.87760s - loss: 0.3101 - accuracy: 0.87 - ETA: 0s - loss: 0.3\n",
      "Epoch 19/150\n",
      "717/717 [==============================] - 1s 956us/step - loss: 0.2961 - accuracy: 0.8812\n",
      "Epoch 20/150\n",
      "717/717 [==============================] - 1s 983us/step - loss: 0.2919 - accuracy: 0.8839\n",
      "Epoch 21/150\n",
      "717/717 [==============================] - 1s 969us/step - loss: 0.2824 - accuracy: 0.8896\n",
      "Epoch 22/150\n",
      "717/717 [==============================] - 1s 956us/step - loss: 0.2882 - accuracy: 0.8882\n",
      "Epoch 23/150\n",
      "717/717 [==============================] - 1s 937us/step - loss: 0.2699 - accuracy: 0.8913\n",
      "Epoch 24/150\n",
      "717/717 [==============================] - 1s 973us/step - loss: 0.2677 - accuracy: 0.8975\n",
      "Epoch 25/150\n",
      "717/717 [==============================] - 1s 993us/step - loss: 0.2827 - accuracy: 0.8841\n",
      "Epoch 26/150\n",
      "717/717 [==============================] - 1s 948us/step - loss: 0.2596 - accuracy: 0.8993\n",
      "Epoch 27/150\n",
      "717/717 [==============================] - 1s 980us/step - loss: 0.2699 - accuracy: 0.8957\n",
      "Epoch 28/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2650 - accuracy: 0.8972\n",
      "Epoch 29/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2550 - accuracy: 0.9050\n",
      "Epoch 30/150\n",
      "717/717 [==============================] - 1s 947us/step - loss: 0.2541 - accuracy: 0.9046\n",
      "Epoch 31/150\n",
      "717/717 [==============================] - 1s 990us/step - loss: 0.2543 - accuracy: 0.9016\n",
      "Epoch 32/150\n",
      "717/717 [==============================] - 1s 988us/step - loss: 0.2648 - accuracy: 0.8993\n",
      "Epoch 33/150\n",
      "717/717 [==============================] - 1s 995us/step - loss: 0.2330 - accuracy: 0.9116\n",
      "Epoch 34/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2432 - accuracy: 0.9064\n",
      "Epoch 35/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2367 - accuracy: 0.9094\n",
      "Epoch 36/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2370 - accuracy: 0.9109\n",
      "Epoch 37/150\n",
      "717/717 [==============================] - 1s 988us/step - loss: 0.2323 - accuracy: 0.9137\n",
      "Epoch 38/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9157\n",
      "Epoch 39/150\n",
      "717/717 [==============================] - 1s 990us/step - loss: 0.2288 - accuracy: 0.9134\n",
      "Epoch 40/150\n",
      "717/717 [==============================] - 1s 967us/step - loss: 0.2337 - accuracy: 0.9152\n",
      "Epoch 41/150\n",
      "717/717 [==============================] - 1s 974us/step - loss: 0.2227 - accuracy: 0.9183\n",
      "Epoch 42/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2236 - accuracy: 0.9179\n",
      "Epoch 43/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2323 - accuracy: 0.9174\n",
      "Epoch 44/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2305 - accuracy: 0.9156\n",
      "Epoch 45/150\n",
      "717/717 [==============================] - 1s 976us/step - loss: 0.2106 - accuracy: 0.9254\n",
      "Epoch 46/150\n",
      "717/717 [==============================] - 1s 996us/step - loss: 0.2086 - accuracy: 0.9228\n",
      "Epoch 47/150\n",
      "717/717 [==============================] - 1s 972us/step - loss: 0.2071 - accuracy: 0.9236\n",
      "Epoch 48/150\n",
      "717/717 [==============================] - 1s 989us/step - loss: 0.2205 - accuracy: 0.9193\n",
      "Epoch 49/150\n",
      "717/717 [==============================] - 1s 942us/step - loss: 0.2039 - accuracy: 0.9227\n",
      "Epoch 50/150\n",
      "717/717 [==============================] - 1s 985us/step - loss: 0.2060 - accuracy: 0.9247\n",
      "Epoch 51/150\n",
      "717/717 [==============================] - 1s 970us/step - loss: 0.1963 - accuracy: 0.9245\n",
      "Epoch 52/150\n",
      "717/717 [==============================] - 1s 965us/step - loss: 0.2040 - accuracy: 0.92820s - loss:\n",
      "Epoch 53/150\n",
      "717/717 [==============================] - 1s 973us/step - loss: 0.1962 - accuracy: 0.9325\n",
      "Epoch 54/150\n",
      "717/717 [==============================] - 1s 972us/step - loss: 0.2122 - accuracy: 0.9218\n",
      "Epoch 55/150\n",
      "717/717 [==============================] - 1s 972us/step - loss: 0.1981 - accuracy: 0.9316\n",
      "Epoch 56/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1967 - accuracy: 0.9295\n",
      "Epoch 57/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1898 - accuracy: 0.9338\n",
      "Epoch 58/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1976 - accuracy: 0.9304\n",
      "Epoch 59/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1798 - accuracy: 0.9334\n",
      "Epoch 60/150\n",
      "717/717 [==============================] - 1s 988us/step - loss: 0.1819 - accuracy: 0.9356\n",
      "Epoch 61/150\n",
      "717/717 [==============================] - 1s 983us/step - loss: 0.1915 - accuracy: 0.9309\n",
      "Epoch 62/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1923 - accuracy: 0.9288\n",
      "Epoch 63/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.1879 - accuracy: 0.9347\n",
      "Epoch 64/150\n",
      "717/717 [==============================] - 1s 855us/step - loss: 0.1890 - accuracy: 0.9325\n",
      "Epoch 65/150\n",
      "717/717 [==============================] - 1s 998us/step - loss: 0.1751 - accuracy: 0.9389\n",
      "Epoch 66/150\n",
      "717/717 [==============================] - 1s 891us/step - loss: 0.1750 - accuracy: 0.93870s - loss: 0.1727 - accuracy: \n",
      "Epoch 67/150\n",
      "717/717 [==============================] - 1s 844us/step - loss: 0.1782 - accuracy: 0.9352\n",
      "Epoch 68/150\n",
      "717/717 [==============================] - 1s 954us/step - loss: 0.1764 - accuracy: 0.9402\n",
      "Epoch 69/150\n",
      "717/717 [==============================] - 1s 934us/step - loss: 0.1841 - accuracy: 0.9336\n",
      "Epoch 70/150\n",
      "717/717 [==============================] - 1s 962us/step - loss: 0.1692 - accuracy: 0.9386\n",
      "Epoch 71/150\n",
      "717/717 [==============================] - 1s 811us/step - loss: 0.1808 - accuracy: 0.9359\n",
      "Epoch 72/150\n",
      "717/717 [==============================] - 0s 666us/step - loss: 0.1744 - accuracy: 0.9377\n",
      "Epoch 73/150\n",
      "717/717 [==============================] - 1s 932us/step - loss: 0.1652 - accuracy: 0.9397\n",
      "Epoch 74/150\n",
      "717/717 [==============================] - 1s 966us/step - loss: 0.1585 - accuracy: 0.9437\n",
      "Epoch 75/150\n",
      "717/717 [==============================] - 1s 785us/step - loss: 0.1647 - accuracy: 0.9402\n",
      "Epoch 76/150\n",
      "717/717 [==============================] - 1s 848us/step - loss: 0.1656 - accuracy: 0.9411\n",
      "Epoch 77/150\n",
      "717/717 [==============================] - 1s 872us/step - loss: 0.1756 - accuracy: 0.9387\n",
      "Epoch 78/150\n",
      "717/717 [==============================] - 0s 689us/step - loss: 0.1707 - accuracy: 0.9382\n",
      "Epoch 79/150\n",
      "717/717 [==============================] - 1s 791us/step - loss: 0.1659 - accuracy: 0.9418\n",
      "Epoch 80/150\n",
      "717/717 [==============================] - 0s 686us/step - loss: 0.1561 - accuracy: 0.9454\n",
      "Epoch 81/150\n",
      "717/717 [==============================] - 1s 751us/step - loss: 0.1800 - accuracy: 0.9348\n",
      "Epoch 82/150\n",
      "717/717 [==============================] - 0s 670us/step - loss: 0.1645 - accuracy: 0.9432\n",
      "Epoch 83/150\n",
      "717/717 [==============================] - 0s 681us/step - loss: 0.1609 - accuracy: 0.9451\n",
      "Epoch 84/150\n",
      "717/717 [==============================] - 0s 673us/step - loss: 0.1583 - accuracy: 0.9422\n",
      "Epoch 85/150\n",
      "717/717 [==============================] - 1s 705us/step - loss: 0.1708 - accuracy: 0.9378\n",
      "Epoch 86/150\n",
      "717/717 [==============================] - 0s 670us/step - loss: 0.1722 - accuracy: 0.9406\n",
      "Epoch 87/150\n",
      "717/717 [==============================] - 1s 709us/step - loss: 0.1632 - accuracy: 0.94300s - loss: 0.1577 - \n",
      "Epoch 88/150\n",
      "717/717 [==============================] - 0s 691us/step - loss: 0.1634 - accuracy: 0.9385\n",
      "Epoch 89/150\n",
      "717/717 [==============================] - 1s 743us/step - loss: 0.1529 - accuracy: 0.9455\n",
      "Epoch 90/150\n",
      "717/717 [==============================] - 0s 670us/step - loss: 0.1654 - accuracy: 0.9404\n",
      "Epoch 91/150\n",
      "717/717 [==============================] - 0s 684us/step - loss: 0.1664 - accuracy: 0.9424\n",
      "Epoch 92/150\n",
      "717/717 [==============================] - 0s 671us/step - loss: 0.1624 - accuracy: 0.9422\n",
      "Epoch 93/150\n",
      "717/717 [==============================] - 1s 744us/step - loss: 0.1679 - accuracy: 0.9437\n",
      "Epoch 94/150\n",
      "717/717 [==============================] - 0s 671us/step - loss: 0.1490 - accuracy: 0.9514\n",
      "Epoch 95/150\n",
      "717/717 [==============================] - 1s 716us/step - loss: 0.1609 - accuracy: 0.9443\n",
      "Epoch 96/150\n",
      "717/717 [==============================] - 1s 701us/step - loss: 0.1486 - accuracy: 0.9489\n",
      "Epoch 97/150\n",
      "717/717 [==============================] - 1s 743us/step - loss: 0.1584 - accuracy: 0.9450\n",
      "Epoch 98/150\n",
      "717/717 [==============================] - 1s 750us/step - loss: 0.1597 - accuracy: 0.9433\n",
      "Epoch 99/150\n",
      "717/717 [==============================] - 1s 705us/step - loss: 0.1554 - accuracy: 0.9456\n",
      "Epoch 100/150\n",
      "717/717 [==============================] - 0s 680us/step - loss: 0.1466 - accuracy: 0.9489\n",
      "Epoch 101/150\n",
      "717/717 [==============================] - 0s 671us/step - loss: 0.1493 - accuracy: 0.9461\n",
      "Epoch 102/150\n",
      "717/717 [==============================] - 0s 676us/step - loss: 0.1557 - accuracy: 0.9454\n",
      "Epoch 103/150\n",
      "717/717 [==============================] - 0s 688us/step - loss: 0.1615 - accuracy: 0.9432\n",
      "Epoch 104/150\n",
      "717/717 [==============================] - 0s 680us/step - loss: 0.1574 - accuracy: 0.9445\n",
      "Epoch 105/150\n",
      "717/717 [==============================] - 1s 716us/step - loss: 0.1439 - accuracy: 0.9519\n",
      "Epoch 106/150\n",
      "717/717 [==============================] - 0s 671us/step - loss: 0.1455 - accuracy: 0.9472\n",
      "Epoch 107/150\n",
      "717/717 [==============================] - 1s 796us/step - loss: 0.1596 - accuracy: 0.9460\n",
      "Epoch 108/150\n",
      "717/717 [==============================] - 0s 685us/step - loss: 0.1574 - accuracy: 0.9441\n",
      "Epoch 109/150\n",
      "717/717 [==============================] - 1s 712us/step - loss: 0.1396 - accuracy: 0.9505\n",
      "Epoch 110/150\n",
      "717/717 [==============================] - 0s 676us/step - loss: 0.1535 - accuracy: 0.9450\n",
      "Epoch 111/150\n",
      "717/717 [==============================] - 0s 690us/step - loss: 0.1511 - accuracy: 0.9451\n",
      "Epoch 112/150\n",
      "717/717 [==============================] - 0s 673us/step - loss: 0.1630 - accuracy: 0.9404\n",
      "Epoch 113/150\n",
      "717/717 [==============================] - 1s 720us/step - loss: 0.1424 - accuracy: 0.9470\n",
      "Epoch 114/150\n",
      "717/717 [==============================] - 1s 741us/step - loss: 0.1419 - accuracy: 0.9516\n",
      "Epoch 115/150\n",
      "717/717 [==============================] - 1s 739us/step - loss: 0.1453 - accuracy: 0.9478\n",
      "Epoch 116/150\n",
      "717/717 [==============================] - 1s 735us/step - loss: 0.1485 - accuracy: 0.9448\n",
      "Epoch 117/150\n",
      "717/717 [==============================] - 1s 796us/step - loss: 0.1475 - accuracy: 0.9476\n",
      "Epoch 118/150\n",
      "717/717 [==============================] - 0s 686us/step - loss: 0.1497 - accuracy: 0.9449\n",
      "Epoch 119/150\n",
      "717/717 [==============================] - 0s 683us/step - loss: 0.1342 - accuracy: 0.9515\n",
      "Epoch 120/150\n",
      "717/717 [==============================] - 0s 674us/step - loss: 0.1452 - accuracy: 0.9508\n",
      "Epoch 121/150\n",
      "717/717 [==============================] - 1s 788us/step - loss: 0.1448 - accuracy: 0.9469\n",
      "Epoch 122/150\n",
      "717/717 [==============================] - 0s 680us/step - loss: 0.1394 - accuracy: 0.9494\n",
      "Epoch 123/150\n",
      "717/717 [==============================] - 1s 781us/step - loss: 0.1512 - accuracy: 0.9495\n",
      "Epoch 124/150\n",
      "717/717 [==============================] - 0s 679us/step - loss: 0.1299 - accuracy: 0.9556\n",
      "Epoch 125/150\n",
      "717/717 [==============================] - 1s 737us/step - loss: 0.1393 - accuracy: 0.9536\n",
      "Epoch 126/150\n",
      "717/717 [==============================] - 1s 767us/step - loss: 0.1426 - accuracy: 0.9495\n",
      "Epoch 127/150\n",
      "717/717 [==============================] - 1s 708us/step - loss: 0.1447 - accuracy: 0.9515\n",
      "Epoch 128/150\n",
      "717/717 [==============================] - 1s 711us/step - loss: 0.1523 - accuracy: 0.9444\n",
      "Epoch 129/150\n",
      "717/717 [==============================] - 1s 698us/step - loss: 0.1329 - accuracy: 0.9528\n",
      "Epoch 130/150\n",
      "717/717 [==============================] - 0s 685us/step - loss: 0.1311 - accuracy: 0.9523\n",
      "Epoch 131/150\n",
      "717/717 [==============================] - 0s 676us/step - loss: 0.1378 - accuracy: 0.9514\n",
      "Epoch 132/150\n",
      "717/717 [==============================] - 1s 699us/step - loss: 0.1437 - accuracy: 0.9506\n",
      "Epoch 133/150\n",
      "717/717 [==============================] - 0s 695us/step - loss: 0.1362 - accuracy: 0.9517\n",
      "Epoch 134/150\n",
      "717/717 [==============================] - 1s 698us/step - loss: 0.1358 - accuracy: 0.9545\n",
      "Epoch 135/150\n",
      "717/717 [==============================] - 1s 698us/step - loss: 0.1411 - accuracy: 0.9533\n",
      "Epoch 136/150\n",
      "717/717 [==============================] - 0s 689us/step - loss: 0.1355 - accuracy: 0.9525\n",
      "Epoch 137/150\n",
      "717/717 [==============================] - 1s 798us/step - loss: 0.1309 - accuracy: 0.9525\n",
      "Epoch 138/150\n",
      "717/717 [==============================] - 0s 667us/step - loss: 0.1489 - accuracy: 0.9491\n",
      "Epoch 139/150\n",
      "717/717 [==============================] - 1s 737us/step - loss: 0.1492 - accuracy: 0.9475\n",
      "Epoch 140/150\n",
      "717/717 [==============================] - 1s 743us/step - loss: 0.1384 - accuracy: 0.9467\n",
      "Epoch 141/150\n",
      "717/717 [==============================] - 1s 800us/step - loss: 0.1323 - accuracy: 0.9563\n",
      "Epoch 142/150\n",
      "717/717 [==============================] - 0s 688us/step - loss: 0.1320 - accuracy: 0.9520\n",
      "Epoch 143/150\n",
      "717/717 [==============================] - 0s 683us/step - loss: 0.1450 - accuracy: 0.9470\n",
      "Epoch 144/150\n",
      "717/717 [==============================] - 1s 705us/step - loss: 0.1442 - accuracy: 0.9484\n",
      "Epoch 145/150\n",
      "717/717 [==============================] - 1s 717us/step - loss: 0.1337 - accuracy: 0.9536\n",
      "Epoch 146/150\n",
      "717/717 [==============================] - 0s 668us/step - loss: 0.1363 - accuracy: 0.9527\n",
      "Epoch 147/150\n",
      "717/717 [==============================] - 0s 675us/step - loss: 0.1351 - accuracy: 0.9518\n",
      "Epoch 148/150\n",
      "717/717 [==============================] - 1s 698us/step - loss: 0.1331 - accuracy: 0.9535\n",
      "Epoch 149/150\n",
      "717/717 [==============================] - 0s 683us/step - loss: 0.1378 - accuracy: 0.9530\n",
      "Epoch 150/150\n",
      "717/717 [==============================] - 0s 672us/step - loss: 0.1427 - accuracy: 0.9487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12d48de6880>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "partial-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 739us/step - loss: 0.1245 - accuracy: 0.9574\n",
      "Training accuracy: 95.74\n",
      "56/56 [==============================] - 0s 821us/step - loss: 0.9539 - accuracy: 0.8185\n",
      "Test accuracy: 81.85\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Training accuracy: %.2f' % (accuracy*100))\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-complexity",
   "metadata": {},
   "source": [
    "Changing activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bulgarian-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "717/717 [==============================] - 1s 967us/step - loss: 0.5462 - accuracy: 0.7220\n",
      "Epoch 2/150\n",
      "717/717 [==============================] - 1s 900us/step - loss: 0.4486 - accuracy: 0.8182\n",
      "Epoch 3/150\n",
      "717/717 [==============================] - 1s 939us/step - loss: 0.3835 - accuracy: 0.8316\n",
      "Epoch 4/150\n",
      "717/717 [==============================] - 1s 945us/step - loss: 0.3498 - accuracy: 0.8572\n",
      "Epoch 5/150\n",
      "717/717 [==============================] - 1s 938us/step - loss: 0.3554 - accuracy: 0.8582\n",
      "Epoch 6/150\n",
      "717/717 [==============================] - 1s 953us/step - loss: 0.3611 - accuracy: 0.8589\n",
      "Epoch 7/150\n",
      "717/717 [==============================] - 1s 956us/step - loss: 0.3464 - accuracy: 0.8630\n",
      "Epoch 8/150\n",
      "717/717 [==============================] - 1s 955us/step - loss: 0.3462 - accuracy: 0.8655\n",
      "Epoch 9/150\n",
      "717/717 [==============================] - 1s 966us/step - loss: 0.3463 - accuracy: 0.8625\n",
      "Epoch 10/150\n",
      "717/717 [==============================] - 1s 935us/step - loss: 0.3486 - accuracy: 0.8603\n",
      "Epoch 11/150\n",
      "717/717 [==============================] - 1s 906us/step - loss: 0.3588 - accuracy: 0.8560\n",
      "Epoch 12/150\n",
      "717/717 [==============================] - 1s 949us/step - loss: 0.3439 - accuracy: 0.8620\n",
      "Epoch 13/150\n",
      "717/717 [==============================] - 1s 973us/step - loss: 0.3340 - accuracy: 0.8690\n",
      "Epoch 14/150\n",
      "717/717 [==============================] - 1s 953us/step - loss: 0.3308 - accuracy: 0.8680\n",
      "Epoch 15/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3387 - accuracy: 0.8696\n",
      "Epoch 16/150\n",
      "717/717 [==============================] - 1s 978us/step - loss: 0.3414 - accuracy: 0.8620\n",
      "Epoch 17/150\n",
      "717/717 [==============================] - 1s 967us/step - loss: 0.3315 - accuracy: 0.8666\n",
      "Epoch 18/150\n",
      "717/717 [==============================] - 1s 945us/step - loss: 0.3481 - accuracy: 0.8667\n",
      "Epoch 19/150\n",
      "717/717 [==============================] - 1s 972us/step - loss: 0.3443 - accuracy: 0.8657\n",
      "Epoch 20/150\n",
      "717/717 [==============================] - 1s 949us/step - loss: 0.3466 - accuracy: 0.8632\n",
      "Epoch 21/150\n",
      "717/717 [==============================] - 1s 998us/step - loss: 0.3549 - accuracy: 0.8576\n",
      "Epoch 22/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3365 - accuracy: 0.8667\n",
      "Epoch 23/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3607 - accuracy: 0.8564\n",
      "Epoch 24/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3363 - accuracy: 0.8664\n",
      "Epoch 25/150\n",
      "717/717 [==============================] - 1s 977us/step - loss: 0.3354 - accuracy: 0.8649\n",
      "Epoch 26/150\n",
      "717/717 [==============================] - 1s 960us/step - loss: 0.3260 - accuracy: 0.8754\n",
      "Epoch 27/150\n",
      "717/717 [==============================] - 1s 928us/step - loss: 0.3414 - accuracy: 0.8636\n",
      "Epoch 28/150\n",
      "717/717 [==============================] - 1s 913us/step - loss: 0.3387 - accuracy: 0.8678\n",
      "Epoch 29/150\n",
      "717/717 [==============================] - 1s 964us/step - loss: 0.3455 - accuracy: 0.8619\n",
      "Epoch 30/150\n",
      "717/717 [==============================] - 1s 939us/step - loss: 0.3516 - accuracy: 0.8595\n",
      "Epoch 31/150\n",
      "717/717 [==============================] - 1s 935us/step - loss: 0.3500 - accuracy: 0.8615\n",
      "Epoch 32/150\n",
      "717/717 [==============================] - 1s 967us/step - loss: 0.3566 - accuracy: 0.8570\n",
      "Epoch 33/150\n",
      "717/717 [==============================] - 1s 958us/step - loss: 0.3323 - accuracy: 0.8722\n",
      "Epoch 34/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3360 - accuracy: 0.8615\n",
      "Epoch 35/150\n",
      "717/717 [==============================] - 1s 967us/step - loss: 0.3482 - accuracy: 0.8619\n",
      "Epoch 36/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3470 - accuracy: 0.8595\n",
      "Epoch 37/150\n",
      "717/717 [==============================] - 1s 976us/step - loss: 0.3442 - accuracy: 0.8567\n",
      "Epoch 38/150\n",
      "717/717 [==============================] - 1s 950us/step - loss: 0.3351 - accuracy: 0.8600\n",
      "Epoch 39/150\n",
      "717/717 [==============================] - 1s 939us/step - loss: 0.3353 - accuracy: 0.8674\n",
      "Epoch 40/150\n",
      "717/717 [==============================] - 1s 926us/step - loss: 0.3491 - accuracy: 0.8569\n",
      "Epoch 41/150\n",
      "717/717 [==============================] - 1s 941us/step - loss: 0.3437 - accuracy: 0.8617\n",
      "Epoch 42/150\n",
      "717/717 [==============================] - 1s 940us/step - loss: 0.3399 - accuracy: 0.8643\n",
      "Epoch 43/150\n",
      "717/717 [==============================] - 1s 927us/step - loss: 0.3516 - accuracy: 0.8584\n",
      "Epoch 44/150\n",
      "717/717 [==============================] - 1s 882us/step - loss: 0.3336 - accuracy: 0.8649\n",
      "Epoch 45/150\n",
      "717/717 [==============================] - 1s 949us/step - loss: 0.3255 - accuracy: 0.8716\n",
      "Epoch 46/150\n",
      "717/717 [==============================] - 1s 987us/step - loss: 0.3355 - accuracy: 0.8609\n",
      "Epoch 47/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.8686\n",
      "Epoch 48/150\n",
      "717/717 [==============================] - 1s 957us/step - loss: 0.3330 - accuracy: 0.8653\n",
      "Epoch 49/150\n",
      "717/717 [==============================] - 1s 948us/step - loss: 0.3359 - accuracy: 0.8619\n",
      "Epoch 50/150\n",
      "717/717 [==============================] - 1s 964us/step - loss: 0.3396 - accuracy: 0.8625\n",
      "Epoch 51/150\n",
      "717/717 [==============================] - 1s 919us/step - loss: 0.3260 - accuracy: 0.8727\n",
      "Epoch 52/150\n",
      "717/717 [==============================] - 1s 940us/step - loss: 0.3375 - accuracy: 0.8634\n",
      "Epoch 53/150\n",
      "717/717 [==============================] - 1s 955us/step - loss: 0.3282 - accuracy: 0.8691\n",
      "Epoch 54/150\n",
      "717/717 [==============================] - 1s 956us/step - loss: 0.3330 - accuracy: 0.8689\n",
      "Epoch 55/150\n",
      "717/717 [==============================] - 1s 985us/step - loss: 0.3317 - accuracy: 0.8649\n",
      "Epoch 56/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8696\n",
      "Epoch 57/150\n",
      "717/717 [==============================] - 1s 990us/step - loss: 0.3353 - accuracy: 0.8677\n",
      "Epoch 58/150\n",
      "717/717 [==============================] - 1s 790us/step - loss: 0.3409 - accuracy: 0.8590\n",
      "Epoch 59/150\n",
      "717/717 [==============================] - 1s 876us/step - loss: 0.3486 - accuracy: 0.8607\n",
      "Epoch 60/150\n",
      "717/717 [==============================] - 1s 922us/step - loss: 0.3396 - accuracy: 0.8670\n",
      "Epoch 61/150\n",
      "717/717 [==============================] - 1s 759us/step - loss: 0.3376 - accuracy: 0.8648\n",
      "Epoch 62/150\n",
      "717/717 [==============================] - 1s 751us/step - loss: 0.3313 - accuracy: 0.8703\n",
      "Epoch 63/150\n",
      "717/717 [==============================] - 1s 838us/step - loss: 0.3328 - accuracy: 0.8661\n",
      "Epoch 64/150\n",
      "717/717 [==============================] - 1s 899us/step - loss: 0.3257 - accuracy: 0.8738\n",
      "Epoch 65/150\n",
      "717/717 [==============================] - 1s 919us/step - loss: 0.3271 - accuracy: 0.8694\n",
      "Epoch 66/150\n",
      "717/717 [==============================] - 1s 737us/step - loss: 0.3361 - accuracy: 0.86280s - loss: 0.3322 \n",
      "Epoch 67/150\n",
      "717/717 [==============================] - 1s 885us/step - loss: 0.3214 - accuracy: 0.8707\n",
      "Epoch 68/150\n",
      "717/717 [==============================] - 1s 819us/step - loss: 0.3308 - accuracy: 0.8719\n",
      "Epoch 69/150\n",
      "717/717 [==============================] - 0s 660us/step - loss: 0.3250 - accuracy: 0.8699\n",
      "Epoch 70/150\n",
      "717/717 [==============================] - 0s 653us/step - loss: 0.3331 - accuracy: 0.8680\n",
      "Epoch 71/150\n",
      "717/717 [==============================] - 1s 715us/step - loss: 0.3272 - accuracy: 0.8683\n",
      "Epoch 72/150\n",
      "717/717 [==============================] - 1s 784us/step - loss: 0.3281 - accuracy: 0.8703\n",
      "Epoch 73/150\n",
      "717/717 [==============================] - 1s 874us/step - loss: 0.3318 - accuracy: 0.8674\n",
      "Epoch 74/150\n",
      "717/717 [==============================] - 1s 883us/step - loss: 0.3249 - accuracy: 0.8738\n",
      "Epoch 75/150\n",
      "717/717 [==============================] - 1s 862us/step - loss: 0.3261 - accuracy: 0.8716\n",
      "Epoch 76/150\n",
      "717/717 [==============================] - 1s 769us/step - loss: 0.3208 - accuracy: 0.8727\n",
      "Epoch 77/150\n",
      "717/717 [==============================] - 1s 710us/step - loss: 0.3329 - accuracy: 0.86900s - loss: 0.3340 - accuracy\n",
      "Epoch 78/150\n",
      "717/717 [==============================] - 1s 768us/step - loss: 0.3103 - accuracy: 0.8739\n",
      "Epoch 79/150\n",
      "717/717 [==============================] - 1s 846us/step - loss: 0.3194 - accuracy: 0.8714\n",
      "Epoch 80/150\n",
      "717/717 [==============================] - 1s 817us/step - loss: 0.3255 - accuracy: 0.8687\n",
      "Epoch 81/150\n",
      "717/717 [==============================] - 1s 699us/step - loss: 0.3266 - accuracy: 0.8654\n",
      "Epoch 82/150\n",
      "717/717 [==============================] - 1s 731us/step - loss: 0.3251 - accuracy: 0.8688\n",
      "Epoch 83/150\n",
      "717/717 [==============================] - 1s 851us/step - loss: 0.3220 - accuracy: 0.8726\n",
      "Epoch 84/150\n",
      "717/717 [==============================] - 1s 782us/step - loss: 0.3240 - accuracy: 0.8698\n",
      "Epoch 85/150\n",
      "717/717 [==============================] - 1s 863us/step - loss: 0.3236 - accuracy: 0.8682\n",
      "Epoch 86/150\n",
      "717/717 [==============================] - 1s 989us/step - loss: 0.3261 - accuracy: 0.8675\n",
      "Epoch 87/150\n",
      "717/717 [==============================] - 1s 893us/step - loss: 0.3186 - accuracy: 0.8700\n",
      "Epoch 88/150\n",
      "717/717 [==============================] - 1s 760us/step - loss: 0.3275 - accuracy: 0.8685\n",
      "Epoch 89/150\n",
      "717/717 [==============================] - 1s 778us/step - loss: 0.3057 - accuracy: 0.8800\n",
      "Epoch 90/150\n",
      "717/717 [==============================] - 1s 774us/step - loss: 0.3175 - accuracy: 0.8701\n",
      "Epoch 91/150\n",
      "717/717 [==============================] - 1s 804us/step - loss: 0.3139 - accuracy: 0.87240s - loss: 0.3128 - accuracy\n",
      "Epoch 92/150\n",
      "717/717 [==============================] - 0s 645us/step - loss: 0.3169 - accuracy: 0.8699\n",
      "Epoch 93/150\n",
      "717/717 [==============================] - 1s 781us/step - loss: 0.3141 - accuracy: 0.8716\n",
      "Epoch 94/150\n",
      "717/717 [==============================] - 1s 713us/step - loss: 0.2942 - accuracy: 0.8852\n",
      "Epoch 95/150\n",
      "717/717 [==============================] - 0s 663us/step - loss: 0.3217 - accuracy: 0.8685\n",
      "Epoch 96/150\n",
      "717/717 [==============================] - 0s 644us/step - loss: 0.2957 - accuracy: 0.8809\n",
      "Epoch 97/150\n",
      "717/717 [==============================] - 1s 727us/step - loss: 0.3075 - accuracy: 0.8750\n",
      "Epoch 98/150\n",
      "717/717 [==============================] - 0s 674us/step - loss: 0.3135 - accuracy: 0.8730\n",
      "Epoch 99/150\n",
      "717/717 [==============================] - 0s 688us/step - loss: 0.3121 - accuracy: 0.8727\n",
      "Epoch 100/150\n",
      "717/717 [==============================] - 1s 750us/step - loss: 0.3085 - accuracy: 0.8703\n",
      "Epoch 101/150\n",
      "717/717 [==============================] - 1s 738us/step - loss: 0.3093 - accuracy: 0.8747\n",
      "Epoch 102/150\n",
      "717/717 [==============================] - 1s 894us/step - loss: 0.3000 - accuracy: 0.8778\n",
      "Epoch 103/150\n",
      "717/717 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8754\n",
      "Epoch 104/150\n",
      "717/717 [==============================] - 1s 878us/step - loss: 0.3023 - accuracy: 0.8745\n",
      "Epoch 105/150\n",
      "717/717 [==============================] - 1s 912us/step - loss: 0.3109 - accuracy: 0.8701\n",
      "Epoch 106/150\n",
      "717/717 [==============================] - 1s 948us/step - loss: 0.2947 - accuracy: 0.8832\n",
      "Epoch 107/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3006 - accuracy: 0.8787\n",
      "Epoch 108/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3027 - accuracy: 0.8780\n",
      "Epoch 109/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2960 - accuracy: 0.8767\n",
      "Epoch 110/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.3026 - accuracy: 0.8744\n",
      "Epoch 111/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2959 - accuracy: 0.8799\n",
      "Epoch 112/150\n",
      "717/717 [==============================] - 1s 972us/step - loss: 0.3106 - accuracy: 0.8713\n",
      "Epoch 113/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2896 - accuracy: 0.8810\n",
      "Epoch 114/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2955 - accuracy: 0.8834\n",
      "Epoch 115/150\n",
      "717/717 [==============================] - 1s 757us/step - loss: 0.2957 - accuracy: 0.8783\n",
      "Epoch 116/150\n",
      "717/717 [==============================] - 1s 852us/step - loss: 0.2941 - accuracy: 0.8762\n",
      "Epoch 117/150\n",
      "717/717 [==============================] - 1s 951us/step - loss: 0.2956 - accuracy: 0.8759\n",
      "Epoch 118/150\n",
      "717/717 [==============================] - 1s 876us/step - loss: 0.2941 - accuracy: 0.8840\n",
      "Epoch 119/150\n",
      "717/717 [==============================] - 1s 766us/step - loss: 0.2997 - accuracy: 0.8755\n",
      "Epoch 120/150\n",
      "717/717 [==============================] - 1s 839us/step - loss: 0.2921 - accuracy: 0.8776\n",
      "Epoch 121/150\n",
      "717/717 [==============================] - 1s 898us/step - loss: 0.2950 - accuracy: 0.8765\n",
      "Epoch 122/150\n",
      "717/717 [==============================] - 1s 864us/step - loss: 0.2961 - accuracy: 0.8776\n",
      "Epoch 123/150\n",
      "717/717 [==============================] - 1s 810us/step - loss: 0.2949 - accuracy: 0.8786\n",
      "Epoch 124/150\n",
      "717/717 [==============================] - 1s 897us/step - loss: 0.2823 - accuracy: 0.8846\n",
      "Epoch 125/150\n",
      "717/717 [==============================] - 1s 871us/step - loss: 0.2901 - accuracy: 0.8826\n",
      "Epoch 126/150\n",
      "717/717 [==============================] - 1s 928us/step - loss: 0.2796 - accuracy: 0.8827\n",
      "Epoch 127/150\n",
      "717/717 [==============================] - 1s 847us/step - loss: 0.2813 - accuracy: 0.8843\n",
      "Epoch 128/150\n",
      "717/717 [==============================] - 1s 704us/step - loss: 0.2889 - accuracy: 0.8841\n",
      "Epoch 129/150\n",
      "717/717 [==============================] - 0s 650us/step - loss: 0.2771 - accuracy: 0.8890\n",
      "Epoch 130/150\n",
      "717/717 [==============================] - 0s 681us/step - loss: 0.2836 - accuracy: 0.8819\n",
      "Epoch 131/150\n",
      "717/717 [==============================] - 1s 754us/step - loss: 0.2810 - accuracy: 0.8854\n",
      "Epoch 132/150\n",
      "717/717 [==============================] - 0s 689us/step - loss: 0.2809 - accuracy: 0.8826\n",
      "Epoch 133/150\n",
      "717/717 [==============================] - 0s 671us/step - loss: 0.2819 - accuracy: 0.8825\n",
      "Epoch 134/150\n",
      "717/717 [==============================] - 0s 639us/step - loss: 0.2721 - accuracy: 0.8870\n",
      "Epoch 135/150\n",
      "717/717 [==============================] - 0s 694us/step - loss: 0.2673 - accuracy: 0.8850\n",
      "Epoch 136/150\n",
      "717/717 [==============================] - 0s 672us/step - loss: 0.2803 - accuracy: 0.8806\n",
      "Epoch 137/150\n",
      "717/717 [==============================] - 1s 754us/step - loss: 0.2591 - accuracy: 0.8944\n",
      "Epoch 138/150\n",
      "717/717 [==============================] - 1s 912us/step - loss: 0.2650 - accuracy: 0.8894\n",
      "Epoch 139/150\n",
      "717/717 [==============================] - 1s 929us/step - loss: 0.2636 - accuracy: 0.8873\n",
      "Epoch 140/150\n",
      "717/717 [==============================] - 1s 762us/step - loss: 0.2682 - accuracy: 0.8868\n",
      "Epoch 141/150\n",
      "717/717 [==============================] - 0s 657us/step - loss: 0.2700 - accuracy: 0.8865\n",
      "Epoch 142/150\n",
      "717/717 [==============================] - 0s 693us/step - loss: 0.2744 - accuracy: 0.8913\n",
      "Epoch 143/150\n",
      "717/717 [==============================] - 1s 836us/step - loss: 0.2759 - accuracy: 0.8831\n",
      "Epoch 144/150\n",
      "717/717 [==============================] - 1s 797us/step - loss: 0.2726 - accuracy: 0.8832\n",
      "Epoch 145/150\n",
      "717/717 [==============================] - 1s 981us/step - loss: 0.2761 - accuracy: 0.8847\n",
      "Epoch 146/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2637 - accuracy: 0.8913\n",
      "Epoch 147/150\n",
      "717/717 [==============================] - 1s 1ms/step - loss: 0.2687 - accuracy: 0.8891\n",
      "Epoch 148/150\n",
      "717/717 [==============================] - 0s 661us/step - loss: 0.2584 - accuracy: 0.8930\n",
      "Epoch 149/150\n",
      "717/717 [==============================] - 1s 718us/step - loss: 0.2655 - accuracy: 0.8863\n",
      "Epoch 150/150\n",
      "717/717 [==============================] - 0s 684us/step - loss: 0.2565 - accuracy: 0.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12d4c098c70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=len(X[0]), activation='sigmoid'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "intellectual-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 709us/step - loss: 0.2577 - accuracy: 0.8897\n",
      "Training accuracy: 88.97\n",
      "56/56 [==============================] - 0s 779us/step - loss: 0.4545 - accuracy: 0.8453\n",
      "Test accuracy: 84.53\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Training accuracy: %.2f' % (accuracy*100))\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
